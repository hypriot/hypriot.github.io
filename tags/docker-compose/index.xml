<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker Compose on Docker Pirates ARMed with explosive stuff</title>
    <link>https://blog.hypriot.com/tags/docker-compose/index.xml</link>
    <description>Recent content in Docker Compose on Docker Pirates ARMed with explosive stuff</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://blog.hypriot.com/tags/docker-compose/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>More Microservices Bliss with Docker 1.12 and Swarm only</title>
      <link>https://blog.hypriot.com/post/more-microservice-bliss-with-docker-1-12/</link>
      <pubDate>Mon, 20 Jun 2016 21:49:00 +0200</pubDate>
      
      <guid>https://blog.hypriot.com/post/more-microservice-bliss-with-docker-1-12/</guid>
      <description>&lt;p&gt;A couple of days ago I wrote a &lt;a href=&#34;https://blog.hypriot.com/post/microservices-bliss-with-docker-and-traefik/&#34;&gt;blog post&lt;/a&gt; about how easy it is to get a microservice application up and running with Docker and a HTTP proxy called Traefik.
I explained how awesome Traefik is because it makes complex setups with HAProxy, Registrator, Consul, etc. a thing of the past.&lt;/p&gt;

&lt;p&gt;I really thought it couldn&amp;rsquo;t get much easier. Oh boy - was I wrong!&lt;/p&gt;

&lt;p&gt;Today as part of the Docker opening keynote Docker demostrated an evolution of Docker Swarm that simplifies this whole scenario even more.
It makes setting up a Docker Swarm Cluster a really simple and straigtforward task.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how this new thing works&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/more-microservices/swarm.jpg&#34; alt=&#34;Docker Swarm&#34; /&gt;
&lt;div style=&#34;text-align:right; font-size: smaller&#34;&gt;Image courtesy of &lt;a href=&#34;https://www.flickr.com/photos/thewakingdragon/&#34;&gt;Brent M&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;If you remember the example from my last post - it consisted of a microservice application made of a frontend and a couple of backend services.
The frontend was a Traefik HTTP proxy that routed the requests to the backend services.
And the backend for the sake of simplicity was just a simple Go-based HTTP webserver that returned the ID of the containers it was running within.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/traefik/microsservice_example_end.jpg&#34; alt=&#34;Traffic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The new Docker Swarm removes the need for a separate HTTP proxy in front of our application containers.
The architecture from above is now slimmed down considerably and looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/more-microservices/architecture_with_swarm.jpg&#34; alt=&#34;With Swarm&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Less moving parts - that is great!&lt;/p&gt;

&lt;p&gt;Still we get built-in loadbalancing to our backend services. We even can access those services from every node in our cluster.
Docker Swarm has a kind of built-in mesh routing integrated that takes care of routing requests to the appropriate backend containers.&lt;/p&gt;

&lt;p&gt;With all the new functionality one could assume that setting up a Docker Swarm cluster got even more complicated than before.
But to the contrary - it got much easier - and that by leaps and bounds.&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t believe me? Just follow along.&lt;/p&gt;

&lt;p&gt;As you might have guessed, we are doing this on Raspberry Pi cluster again.
I am using a homegrown version of Docker 1.12 that I installed on my Raspberry Pi.
Hopefully when Docker 1.12 is not a release candidate anymore we will have a version for you ready, too.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what we have:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker version
Client:
 Version:      1.12.0-rc1
 API version:  1.24
 Go version:   go1.6.2
 Git commit:   1f136c1-unsupported
 Built:        Wed Jun 15 15:35:51 2016
 OS/Arch:      linux/arm

Server:
 Version:      1.12.0-rc1
 API version:  1.24
 Go version:   go1.6.2
 Git commit:   1f136c1-unsupported
 Built:        Wed Jun 15 15:35:51 2016
 OS/Arch:      linux/arm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great. Docker 1.12 RC1 is ready. We should have everything we need to get started.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if we can find out if we have same new features hidden in our Docker CLI.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker
Usage: docker [OPTIONS] COMMAND [arg...]
       docker [ --help | -v | --version ]

A self-sufficient runtime for containers.
    ...
    service   Manage Docker services
    ...
    stats     Display a live stream of container(s) resource usage statistics
    ...
    swarm     Manage Docker Swarm
    ...
    update    Update configuration of one or more containers

Run &#39;docker COMMAND --help&#39; for more information on a command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I removed the lines of the command output that have not changed compared to the previous release. What remains though is still pretty interesting&amp;hellip;&lt;/p&gt;

&lt;p&gt;We now seem to have a &amp;lsquo;docker swarm&amp;rsquo; command.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what it is all about&amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker swarm

Usage:  docker swarm COMMAND

Manage Docker Swarm

Options:
      --help   Print usage

Commands:
  init        Initialize a Swarm.
  join        Join a Swarm as a node and/or manager.
  update      update the Swarm.
  leave       Leave a Swarm.
  inspect     Inspect the Swarm

Run &#39;docker swarm COMMAND --help&#39; for more information on a command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So &amp;lsquo;Initialize a Swarm.&amp;rsquo; seems to be exactly what we want. Let&amp;rsquo;s start with this one.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker swarm init
Swarm initialized: current node (1njlvzi9rk2syv3xojw217o0g) is now a manager.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have a Swarm manger node running it is time to add some more nodes to the cluster.&lt;br /&gt;
And it is really simple as well.&lt;/p&gt;

&lt;p&gt;Just go to another node of your cluster and execute:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi1 $ docker swarm join pi6:2377
This node joined a Swarm as a worker.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this command we basically just tell new nodes that they should join the Swarm Manager node on which we created the inital Swarm cluster.
In the background Docker Swarm now does some work for us.&lt;/p&gt;

&lt;p&gt;For instance it sets up encrypted communication channels between the cluster nodes. We do not need to manage TLS certificates on our own.&lt;/p&gt;

&lt;p&gt;Everybody who knows how involved it could be to get a Docker Swarm cluster up running in the past should realize how easy it is now.&lt;/p&gt;

&lt;p&gt;Still we are not yet finished.&lt;/p&gt;

&lt;p&gt;A &amp;lsquo;docker info&amp;rsquo; on our Swarm Manager node reveals some interesting tidbits.
Again I removed the uninteresting parts for brevity.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker info
...
Swarm: active
 NodeID: 1njlvzi9rk2syv3xojw217o0g
 IsManager: Yes
 Managers: 1
 Nodes: 2
 CACertHash: sha256:de4e2bff3b63700aad01df97bbe0397f131aabed5fabb7732283f044472323fc
...
Kernel Version: 4.4.10-hypriotos-v7+
Operating System: Raspbian GNU/Linux 8 (jessie)
OSType: linux
Architecture: armv7l
CPUs: 4
Total Memory: 925.4 MiB
Name: pi6
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see we now have a new &amp;lsquo;Swarm&amp;rsquo; part in the &amp;lsquo;docker info&amp;rsquo; output.
It tells us that our current node is a Swarm Manager node and that the cluster is composed of two cluster nodes in total.&lt;/p&gt;

&lt;p&gt;On our second node it looks a bit different as it is not a Manager node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Swarm: active
 NodeID: 3fmwt4taurwxczr2icboojz8g
 IsManager: No
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Until now we just have an interesting, but still very empty Swarm cluster.
Let&amp;rsquo;s change that.&lt;/p&gt;

&lt;p&gt;Before we start let me introduce you to the concept of a service that is also new abstraction with Docker 1.12.
You might have seen a hint of it already in the output of the Docker command above.
Yes, it is the &amp;lsquo;docker service&amp;rsquo; command that I am talking about.
A Docker service is basically just a bit of software running in a container that offers its &amp;lsquo;service&amp;rsquo; to the outside world and runs on a Swarm cluster.&lt;/p&gt;

&lt;p&gt;Such a service can consist of just one container or of multiple containers.
In the latter case we get high availability and/or loadbalancing for our service out of the box.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s create such a service based on our &amp;lsquo;whoami&amp;rsquo; image from my last blog post.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service create --name whoami -p 80:8000 hypriot/rpi-whoami
buy0q65lw7nshm76kvy5imxk3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the help of the &amp;lsquo;docker swarm ls&amp;rsquo; command we can check the status of our new service.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service ls
ID            NAME    SCALE  IMAGE               COMMAND
buy0q65lw7ns  whoami  1      hypriot/rpi-whoami
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s check if we can request the index page from our whoami container by sending I http request via curl to the ip of eth0 network interface.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ curl http://192.168.178.24
I&#39;m 1b6df814c654
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And it is working. Awesome!&lt;/p&gt;

&lt;p&gt;Those who followed along with keen eyes will have noticed the &amp;lsquo;SCALE&amp;rsquo; part in the header line of the &amp;lsquo;docker swarm ls&amp;rsquo; command.
It seems as we can scale our service somehow.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service scale whoami=5
whoami scaled to 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OK. Let&amp;rsquo;s check what we have now:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service ls
ID            NAME    SCALE  IMAGE               COMMAND
buy0q65lw7ns  whoami  5      hypriot/rpi-whoami

root@pi6 $ for i in {1..5}; do curl http://192.168.178.24; done
I&#39;m 8db1657e8517
I&#39;m e1863a2be88d
I&#39;m 1b6df814c654
I&#39;m 8db1657e8517
I&#39;m e1863a2be88d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is pretty neat.&lt;/p&gt;

&lt;p&gt;But this is not just way more simple than the old Swarm, it also feels much more snappier and faster when executing commands.
And remember I am working on Raspberry Pi&amp;rsquo;s and not on a beefy server like you would propably work on.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how this looks from the perspective of an individual Docker engine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS               NAMES
e1863a2be88d        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             2 minutes ago       Up 2 minutes        8000/tcp            whoami.4.0lg12zndbal72exqe08r9wvpg
8db1657e8517        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             2 minutes ago       Up 2 minutes        8000/tcp            whoami.5.5z6mvsrdy73m5w24icgsqc8i2
1b6df814c654        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             8 minutes ago       Up 8 minutes        8000/tcp            whoami.1.bg4qlpiye6h6uxyf8cmkwuh52
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see from the five containers that were started three reside on &amp;lsquo;pi6&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if we can find the rest:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi1 docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS               NAMES
db411a119c0a        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             6 minutes ago       Up 6 minutes        8000/tcp            whoami.2.2tf7yhmx9haol7e2b7xib2emj
0a4bf32fa9c4        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             6 minutes ago       Up 6 minutes        8000/tcp            whoami.3.2r6mm091c2ybr0f9jz4qaxw9k
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So what happens when I just leave the Swarm cluster on &amp;lsquo;pi1&amp;rsquo;?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi1 docker swarm leave
Node left the default swarm.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now I should be two containers short, right?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what we have on our remaining node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS               NAMES
58620e3d533c        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             46 seconds ago      Up 43 seconds       8000/tcp            whoami.2.cgc4e2ixulc2f3ehr4laoursg
acc9b523f434        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             46 seconds ago      Up 43 seconds       8000/tcp            whoami.3.67bhlo3nwgehthi3bg5bfdzue
e1863a2be88d        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             8 minutes ago       Up 8 minutes        8000/tcp            whoami.4.0lg12zndbal72exqe08r9wvpg
8db1657e8517        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             8 minutes ago       Up 8 minutes        8000/tcp            whoami.5.5z6mvsrdy73m5w24icgsqc8i2
1b6df814c654        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             15 minutes ago      Up 14 minutes       8000/tcp            whoami.1.bg4qlpiye6h6uxyf8cmkwuh52
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What we witnessed here is the same what would have happened if we just had a failing &amp;lsquo;pi1&amp;rsquo; node.
All the containers that were running on node &amp;lsquo;pi1&amp;rsquo; were migrated to the remaining cluster nodes automatically.
That&amp;rsquo;s pretty impressive.&lt;/p&gt;

&lt;p&gt;So to recap what we just did:&lt;br /&gt;
We created a small dynamic microservice applications with just the plain Docker.
Docker Swarm is now integrated into the Docker-Engine instead of being a separate piece of software.
In many cases this makes a separate proxy for the backend services of your application obsolete. No more nginx, HAProxy or Traefik. Sorry to see you go&amp;hellip;&lt;/p&gt;

&lt;p&gt;Despite having fewer moving parts we now have additional load balancing and high availability features built-in.
I am really looking forward to find out what else there is in store with the new Docker Swarm and how it works together with Docker Compose.&lt;/p&gt;

&lt;p&gt;But that&amp;rsquo;s a story for another day&amp;hellip;&lt;/p&gt;

&lt;p&gt;As always use the comments below to give us feedback and share the news about this release on Twitter, Facebook or Google+.&lt;/p&gt;

&lt;p&gt;Govinda &lt;a href=&#34;https://twitter.com/_beagile_&#34;&gt;@_beagile__&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Microservices Bliss with Docker and Traefik</title>
      <link>https://blog.hypriot.com/post/microservices-bliss-with-docker-and-traefik/</link>
      <pubDate>Tue, 07 Jun 2016 09:15:00 +0000</pubDate>
      
      <guid>https://blog.hypriot.com/post/microservices-bliss-with-docker-and-traefik/</guid>
      <description>&lt;p&gt;A couple of weeks ago I found this really nice and neat HTTP reverse proxy called &lt;a href=&#34;https://docs.traefik.io/&#34;&gt;Traefik&lt;/a&gt;.
It is meant to act as frontend proxy for microservices that are provided by a dynamic backend like Docker.&lt;/p&gt;

&lt;p&gt;Did you realize the important part of the last sentence was &lt;strong&gt;dynamic&lt;/strong&gt;?&lt;/p&gt;

&lt;p&gt;What makes Traefik really special is its ability of adding and removing container backend services by listening to Docker events.
So whenever a Docker container is started or stopped Traefik knows about it and adds the container to its list of active backend services.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/traefik/architecture.png&#34; alt=&#34;Traffic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;With this ability Traefik can replace much more complicated setups based on Nginx or HAProxy that have to use additional tools like
&lt;a href=&#34;https://github.com/gliderlabs/registrator&#34;&gt;Registrator&lt;/a&gt;, &lt;a href=&#34;https://www.consul.io/&#34;&gt;Consul&lt;/a&gt; and &lt;a href=&#34;https://github.com/hashicorp/consul-template&#34;&gt;Consul-Template&lt;/a&gt; to achieve the same kind of functionality.&lt;/p&gt;

&lt;p&gt;So let me show you with a simple microservice example how easy it is to get started with Traefik&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;As you can see in the following architecture overview we will have a simple HTTP service that answers incoming HTTP requests.&lt;/p&gt;

&lt;p&gt;We have multiple backend services that are running on different physical nodes for high availability and loadbalancing reasons.
Traefik serves as a frontend proxy that loadbalances incoming requests to the available backend services.&lt;/p&gt;

&lt;p&gt;Traefik as well as the backend services will run on top of a Docker Swarm cluster as containers.
In this example each backend service will answer with their individual container ID to make it easy to see which one answered.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/traefik/microsservice_example_end.jpg&#34; alt=&#34;Traffic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So to get started we need a running Docker Swarm Cluster first.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-docker-swarm-cluster&#34;&gt;Creating a Docker Swarm Cluster&lt;/h2&gt;

&lt;p&gt;One of fastest and easiest ways to get a Docker Swarm cluster running is to use our &lt;a href=&#34;https://github.com/hypriot/cluster-lab&#34;&gt;Hypriot Cluster Lab&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As the Cluster Lab comes already preinstalled with out latest HypriotOS &amp;ldquo;Barbossa&amp;rdquo; release for the Raspberr Pi I will show you how to set up a Swarm Cluster with that.&lt;/p&gt;

&lt;p&gt;To follow along you will need at least three Raspberry Pi&amp;rsquo;s. I will use my Pico-Cluster with five nodes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/traefik/picocluster.jpg&#34; alt=&#34;Traffic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The first step is flashing the necessary SD card images with HypriotOS.&lt;/p&gt;

&lt;p&gt;Clone the Hypriot flash repository and change into the appropriate folder for the operating system you are using to flash the SD cards.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/hypriot/flash.gi://github.com/hypriot/flash.git
$ cd flash/Darwin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the flash tool ready we now can prepare the SD card for our &lt;strong&gt;leader node&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./flash --hostname cl-leader https://github.com/hypriot/image-builder-rpi/releases/download/v0.8.0/hypriotos-rpi-v0.8.0.img.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Repeat the process for the &lt;strong&gt;follower nodes&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in {1..4} do; ./flash --hostname cl-follower${i} https://github.com/hypriot/image-builder-rpi/releases/download/v0.8.0/hypriotos-rpi-v0.8.0.img.zip; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While the SD cards for the follower nodes are still being flashed you can already start the leader node.&lt;/p&gt;

&lt;p&gt;SSH into the leader and become root user:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh pirate@cl-leader.local
$ sudo su
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make the Cluster Lab work with Traefik we need to update to the most recent version:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apt-get update
$ apt-get install hypriot-cluster-lab=0.2.13-1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then start the Hypriot Cluster Lab with verbose output logging enabled:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ VERBOSE=true cluster-lab start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While the Cluster Lab starts you can see how it configures itself and does a number of self-tests.
If not all steps are green stop it and start it again. If that fails, too, have a look at our &lt;a href=&#34;https://github.com/hypriot/cluster-lab#troubleshooting&#34;&gt;troubleshooting section&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After the leader node is ready, it is time to boot the rest of our nodes and update and start the Cluster Lab in the same fashion.
So go ahead and come back when your are done.&lt;/p&gt;

&lt;p&gt;Allright, We can now check if we really have a healthy five nodes Swarm Cluster by executing the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOCKER_HOST=tcp://192.168.200.1:2378 docker info | grep Nodes
Nodes: 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And voila we now really have five nodes in our cluster.
Congrats!&lt;/p&gt;

&lt;p&gt;As you made it so far the rest will be a piece of a cake!&lt;/p&gt;

&lt;h3 id=&#34;setting-up-our-microservice-app-with-traefik&#34;&gt;Setting up our microservice app with Traefik&lt;/h3&gt;

&lt;p&gt;Our example microservice application consists of two parts. The Traefik frontend and the WhoAmI application backend.
For both parts I have prepared images for you that can be pulled from the Docker Hub.&lt;/p&gt;

&lt;p&gt;The Traefik image is called &lt;a href=&#34;https://hub.docker.com/r/hypriot/rpi-traefik/&#34;&gt;hypriot/rpi-traefik&lt;/a&gt; and the WhoAmI image is called &lt;a href=&#34;https://hub.docker.com/r/hypriot/rpi-whoami/&#34;&gt;hypriot/rpi-whoami&lt;/a&gt;.
The Dockerfiles for both images can be found on Github in the &lt;a href=&#34;https://github.com/hypriot&#34;&gt;related repositories&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Because both Dockerfiles are a fine example of how easy it is to create Docker images for Golang based software I will
show them here, too.&lt;/p&gt;

&lt;p&gt;Dockerfile for &amp;ldquo;rpi-traefik&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM hypriot/rpi-alpine-scratch
RUN apk update &amp;amp;&amp;amp;\
    apk upgrade &amp;amp;&amp;amp;\
    apk add ca-certificates &amp;amp;&amp;amp;\
    rm -rf /var/cache/apk/*
ADD https://github.com/containous/traefik/releases/download/v1.0.0-beta.771/traefik_linux-arm /traefik
RUN chmod +x /traefik
EXPOSE 80 8080
ENTRYPOINT [&amp;quot;/traefik&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we just add the Traefik binary on top of an Alpine linux image. The result is an image that is already quite small with about 41 MB.
It propably could be made even smaller by ensuring that the Traefik binary is compiled as a static binary and then putting it into an empty scratch image.&lt;/p&gt;

&lt;p&gt;You can see how this can be done with the next Dockerfile for the WhoAmI image:&lt;/p&gt;

&lt;p&gt;Dockerfile for &amp;ldquo;rpi-whoami&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM scratch

ADD http /http

ENV PORT 8000
EXPOSE 8000

CMD [&amp;quot;/http&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With about 3 MB the resulting image is really small.&lt;/p&gt;

&lt;p&gt;Well, now it is time to put this all together in a Docker Compose application.&lt;/p&gt;

&lt;p&gt;Clone the following repository on you cluster leader:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/hypriot/rpi-cluster-lab-demos
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When the cloning is finished change into the &amp;lsquo;traefik&amp;rsquo; folder and use Docker Compose to start our application on top of our little Docker Swarm cluster:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd rpi-cluster-lab-demos/traefik
$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose up -d
Creating network &amp;quot;traefik_default&amp;quot; with the default driver
Creating traefik_traefik_1
Creating traefik_whoami_1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this command Docker Compose should start two containers.
One Traefik container on our leader and one WhoAmi container on one of our follower nodes.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s check if that really happened:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker ps | grep &#39;traefik\|whoami&#39;
cba8d9a7d8f7        hypriot/rpi-whoami         &amp;quot;/http&amp;quot;                  About a minute ago   Up About a minute   8000/tcp                                                 cl-follower1/traefik_whoami_1
7dc2b48a24e2        hypriot/rpi-traefik        &amp;quot;/traefik --web --doc&amp;quot;   About a minute ago   Up About a minute   192.168.200.1:80-&amp;gt;80/tcp, 192.168.200.1:8080-&amp;gt;8080/tcp   cl-leader/traefik_traefik_1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks good. So let&amp;rsquo;s test our application by flinging some HTTP request towards our frontend:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in {1..5}; do curl -H Host:whoami.docker.localhost http://192.168.200.1; done
I&#39;am f72892c9187c
I&#39;am f72892c9187c
I&#39;am f72892c9187c
I&#39;am f72892c9187c
I&#39;am f72892c9187c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see it is always the same backend container which is responding and that&amp;rsquo;s just as it should be.&lt;/p&gt;

&lt;p&gt;Next we are going to increase the number of backend containers with the help of Docker Compose scale command.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose scale whoami=5
Creating and starting traefik_whoami_2 ... done
Creating and starting traefik_whoami_3 ... done
Creating and starting traefik_whoami_4 ... done
Creating and starting traefik_whoami_5 ... done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can watch as Docker Compose tells Docker Swarm to spin up more containers.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s verify again if we now have five backend containers running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in {1..5}; do curl -H Host:whoami.docker.localhost http://192.168.200.1; done
I&#39;m 5d829fecbdaa
I&#39;m 5eb115353885
I&#39;m e0313ac24554
I&#39;m 642b5d2c8d09
I&#39;m f72892c9187c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect. Obviously Traefik did recognise that we started more containers and made them available to the frontend automatically.&lt;/p&gt;

&lt;p&gt;We can see what happened by looking at the logs of the Traefik container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose logs traefik
...
traefik_1  | time=&amp;quot;2016-06-07T06:50:38Z&amp;quot; level=debug msg=&amp;quot;Configuration received from provider docker: {\&amp;quot;backends\&amp;quot;:{\&amp;quot;backend-whoami\&amp;quot;:{\&amp;quot;servers\&amp;quot;:{\&amp;quot;server-traefik_whoami_1\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.3:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_2\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.5:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_3\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.6:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_4\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.4:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_5\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.7:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1}}}},\&amp;quot;frontends\&amp;quot;:{\&amp;quot;frontend-Host-whoami-docker-localhost\&amp;quot;:{\&amp;quot;backend\&amp;quot;:\&amp;quot;backend-whoami\&amp;quot;,\&amp;quot;routes\&amp;quot;:{\&amp;quot;route-frontend-Host-whoami-docker-localhost\&amp;quot;:{\&amp;quot;rule\&amp;quot;:\&amp;quot;Host:whoami.docker.localhost\&amp;quot;}},\&amp;quot;passHostHeader\&amp;quot;:true}}}&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:38Z&amp;quot; level=debug msg=&amp;quot;Last docker config received less than 2s, waiting...&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Waited for docker config, OK&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating frontend frontend-Host-whoami-docker-localhost&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Wiring frontend frontend-Host-whoami-docker-localhost to entryPoint http&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating route route-frontend-Host-whoami-docker-localhost Host:whoami.docker.localhost&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating backend backend-whoami&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating load-balancer wrr&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_4 at http://10.0.0.4:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_3 at http://10.0.0.6:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_2 at http://10.0.0.5:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_1 at http://10.0.0.3:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_5 at http://10.0.0.7:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=info msg=&amp;quot;Server configuration reloaded on :80&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looking at the logs we can now clearly see how Traefik catched the Docker event and how it reacted.&lt;/p&gt;

&lt;p&gt;Isnt&amp;rsquo; awesome?&lt;/p&gt;

&lt;p&gt;OK. So this was basically our quick tour on how to do set up a simple microservice example with Docker and Traefik.&lt;/p&gt;

&lt;p&gt;The only thing that is left for us now is to clean up again.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose down -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Did you notice the &amp;lsquo;-v&amp;rsquo; option? This seems to be really important as it cleans up all the containers including the overlay network that was created for us.
Without the &amp;lsquo;-v&amp;rsquo; option we would get an error the next time we start the application again with Docker Compose.&lt;/p&gt;

&lt;p&gt;It is also a good idea to stop the Cluster Lab on all nodes before you switch of your Raspberry Pi&amp;rsquo;s.&lt;/p&gt;

&lt;p&gt;So do a&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cluster-lab stop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;on all your cluster nodes.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s just amazing how many interesting technologies we used in this small blog post.
And it wasn&amp;rsquo;t to hard to get them running together, wasn&amp;rsquo;t it?&lt;/p&gt;

&lt;p&gt;That is mostly due to the work the &lt;a href=&#34;https://github.com/hypriot/cluster-lab&#34;&gt;Hypriot Cluster Lab&lt;/a&gt; does for us and of course under the hood it is the Docker-Engine, Docker-Swarm and Docker-Compose that let&amp;rsquo;s us do so much with so little effort.&lt;/p&gt;

&lt;p&gt;So make sure to give our Hypriot Cluster Lab a spin and try some of the examples in our &lt;a href=&#34;https://github.com/hypriot/rpi-cluster-lab-demos&#34;&gt;Hypriot Cluster Lab Demos&lt;/a&gt; repository or add some of your own. Pull requests are always welcome.&lt;/p&gt;

&lt;p&gt;As always use the comments below to give us feedback and share the news about this release on Twitter, Facebook or Google+.&lt;/p&gt;

&lt;p&gt;Govinda &lt;a href=&#34;https://twitter.com/_beagile_&#34;&gt;@_beagile__&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>