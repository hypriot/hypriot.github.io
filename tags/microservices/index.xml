<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Microservices on Docker Pirates ARMed with explosive stuff</title>
    <link>http://blog.hypriot.com/tags/microservices/</link>
    <description>Recent content in Microservices on Docker Pirates ARMed with explosive stuff</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Jun 2016 21:49:00 +0200</lastBuildDate>
    <atom:link href="http://blog.hypriot.com/tags/microservices/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>More Microservices Bliss with Docker 1.12 and Swarm only</title>
      <link>http://blog.hypriot.com/post/more-microservice-bliss-with-docker-1-12/</link>
      <pubDate>Mon, 20 Jun 2016 21:49:00 +0200</pubDate>
      
      <guid>http://blog.hypriot.com/post/more-microservice-bliss-with-docker-1-12/</guid>
      <description>&lt;p&gt;A couple of days ago I wrote a &lt;a href=&#34;http://blog.hypriot.com/post/microservices-bliss-with-docker-and-traefik/&#34;&gt;blog post&lt;/a&gt; about how easy it is to get a microservice application up and running with Docker and a HTTP proxy called Traefik.
I explained how awesome Traefik is because it makes complex setups with HAProxy, Registrator, Consul, etc. a thing of the past.&lt;/p&gt;

&lt;p&gt;I really thought it couldn&amp;rsquo;t get much easier. Oh boy - was I wrong!&lt;/p&gt;

&lt;p&gt;Today as part of the Docker opening keynote Docker demostrated an evolution of Docker Swarm that simplifies this whole scenario even more.
It makes setting up a Docker Swarm Cluster a really simple and straigtforward task.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how this new thing works&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/more-microservices/swarm.jpg&#34; alt=&#34;Docker Swarm&#34; /&gt;

&lt;div style=&#34;text-align:right; font-size: smaller&#34;&gt;Image courtesy of &lt;a href=&#34;https://www.flickr.com/photos/thewakingdragon/&#34;&gt;Brent M&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;If you remember the example from my last post - it consisted of a microservice application made of a frontend and a couple of backend services.
The frontend was a Traefik HTTP proxy that routed the requests to the backend services.
And the backend for the sake of simplicity was just a simple Go-based HTTP webserver that returned the ID of the containers it was running within.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/traefik/microsservice_example_end.jpg&#34; alt=&#34;Traffic&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The new Docker Swarm removes the need for a separate HTTP proxy in front of our application containers.
The architecture from above is now slimmed down considerably and looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/more-microservices/architecture_with_swarm.jpg&#34; alt=&#34;With Swarm&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Less moving parts - that is great!&lt;/p&gt;

&lt;p&gt;Still we get built-in loadbalancing to our backend services. We even can access those services from every node in our cluster.
Docker Swarm has a kind of built-in mesh routing integrated that takes care of routing requests to the appropriate backend containers.&lt;/p&gt;

&lt;p&gt;With all the new functionality one could assume that setting up a Docker Swarm cluster got even more complicated than before.
But to the contrary - it got much easier - and that by leaps and bounds.&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t believe me? Just follow along.&lt;/p&gt;

&lt;p&gt;As you might have guessed, we are doing this on Raspberry Pi cluster again.
I am using a homegrown version of Docker 1.12 that I installed on my Raspberry Pi.
Hopefully when Docker 1.12 is not a release candidate anymore we will have a version for you ready, too.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what we have:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker version
Client:
 Version:      1.12.0-rc1
 API version:  1.24
 Go version:   go1.6.2
 Git commit:   1f136c1-unsupported
 Built:        Wed Jun 15 15:35:51 2016
 OS/Arch:      linux/arm

Server:
 Version:      1.12.0-rc1
 API version:  1.24
 Go version:   go1.6.2
 Git commit:   1f136c1-unsupported
 Built:        Wed Jun 15 15:35:51 2016
 OS/Arch:      linux/arm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great. Docker 1.12 RC1 is ready. We should have everything we need to get started.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if we can find out if we have same new features hidden in our Docker CLI.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker
Usage: docker [OPTIONS] COMMAND [arg...]
       docker [ --help | -v | --version ]

A self-sufficient runtime for containers.
    ...
    service   Manage Docker services
    ...
    stats     Display a live stream of container(s) resource usage statistics
    ...
    swarm     Manage Docker Swarm
    ...
    update    Update configuration of one or more containers

Run &#39;docker COMMAND --help&#39; for more information on a command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I removed the lines of the command output that have not changed compared to the previous release. What remains though is still pretty interesting&amp;hellip;&lt;/p&gt;

&lt;p&gt;We now seem to have a &amp;lsquo;docker swarm&amp;rsquo; command.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what it is all about&amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker swarm

Usage:  docker swarm COMMAND

Manage Docker Swarm

Options:
      --help   Print usage

Commands:
  init        Initialize a Swarm.
  join        Join a Swarm as a node and/or manager.
  update      update the Swarm.
  leave       Leave a Swarm.
  inspect     Inspect the Swarm

Run &#39;docker swarm COMMAND --help&#39; for more information on a command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So &amp;lsquo;Initialize a Swarm.&amp;rsquo; seems to be exactly what we want. Let&amp;rsquo;s start with this one.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker swarm init
Swarm initialized: current node (1njlvzi9rk2syv3xojw217o0g) is now a manager.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have a Swarm manger node running it is time to add some more nodes to the cluster.&lt;br /&gt;
And it is really simple as well.&lt;/p&gt;

&lt;p&gt;Just go to another node of your cluster and execute:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi1 $ docker swarm join pi6:2377
This node joined a Swarm as a worker.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this command we basically just tell new nodes that they should join the Swarm Manager node on which we created the inital Swarm cluster.
In the background Docker Swarm now does some work for us.&lt;/p&gt;

&lt;p&gt;For instance it sets up encrypted communication channels between the cluster nodes. We do not need to manage TLS certificates on our own.&lt;/p&gt;

&lt;p&gt;Everybody who knows how involved it could be to get a Docker Swarm cluster up running in the past should realize how easy it is now.&lt;/p&gt;

&lt;p&gt;Still we are not yet finished.&lt;/p&gt;

&lt;p&gt;A &amp;lsquo;docker info&amp;rsquo; on our Swarm Manager node reveals some interesting tidbits.
Again I removed the uninteresting parts for brevity.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker info
...
Swarm: active
 NodeID: 1njlvzi9rk2syv3xojw217o0g
 IsManager: Yes
 Managers: 1
 Nodes: 2
 CACertHash: sha256:de4e2bff3b63700aad01df97bbe0397f131aabed5fabb7732283f044472323fc
...
Kernel Version: 4.4.10-hypriotos-v7+
Operating System: Raspbian GNU/Linux 8 (jessie)
OSType: linux
Architecture: armv7l
CPUs: 4
Total Memory: 925.4 MiB
Name: pi6
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see we now have a new &amp;lsquo;Swarm&amp;rsquo; part in the &amp;lsquo;docker info&amp;rsquo; output.
It tells us that our current node is a Swarm Manager node and that the cluster is composed of two cluster nodes in total.&lt;/p&gt;

&lt;p&gt;On our second node it looks a bit different as it is not a Manager node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Swarm: active
 NodeID: 3fmwt4taurwxczr2icboojz8g
 IsManager: No
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unil now we just have an interesting, but still very empty Swarm cluster.
Let&amp;rsquo;s change that.&lt;/p&gt;

&lt;p&gt;Before we start let me introduce you to the concept of a service that is also new abstraction with Docker 1.12.
You might have seen a hint of it already in the output of the Docker command above.
Yes, it is the &amp;lsquo;docker service&amp;rsquo; command that I am talking about.
A Docker service is basically just a bit of software running in a container that offers its &amp;lsquo;service&amp;rsquo; to the outside world and runs on a Swarm cluster.&lt;/p&gt;

&lt;p&gt;Such a service can consist of just one container or of multiple containers.
In the latter case we get high availability and/or loadbalancing for our service out of the box.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s create such a service based on our &amp;lsquo;whoami&amp;rsquo; image from my last blog post.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service create --name whoami -p 80:8000 hypriot/rpi-whoami
buy0q65lw7nshm76kvy5imxk3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the help of the &amp;lsquo;docker swarm ls&amp;rsquo; command we can check the status of our new service.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service ls
ID            NAME    SCALE  IMAGE               COMMAND
buy0q65lw7ns  whoami  1      hypriot/rpi-whoami
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s check if we can request the index page from our whoami container by sending I http request via curl to the ip of eth0 network interface.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ curl http://192.168.178.24
I&#39;m 1b6df814c654
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And it is working. Awesome!&lt;/p&gt;

&lt;p&gt;Those who followed along with keen eyes will have noticed the &amp;lsquo;SCALE&amp;rsquo; part in the header line of the &amp;lsquo;docker swarm ls&amp;rsquo; command.
It seems as we can scale our service somehow.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service scale whoami=5
whoami scaled to 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OK. Let&amp;rsquo;s check what we have now:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service ls
ID            NAME    SCALE  IMAGE               COMMAND
buy0q65lw7ns  whoami  5      hypriot/rpi-whoami

root@pi6 $ for i in {1..5}; do curl http://192.168.178.24; done
I&#39;m 8db1657e8517
I&#39;m e1863a2be88d
I&#39;m 1b6df814c654
I&#39;m 8db1657e8517
I&#39;m e1863a2be88d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is pretty neat.&lt;/p&gt;

&lt;p&gt;But this is not just way more simple than the old Swarm, it also feels much more snappier and faster when executing commands.
And remember I am working on Raspberry Pi&amp;rsquo;s and not on a beefy server like you would propably work on.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how this looks from the perspective of an individual Docker engine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS               NAMES
e1863a2be88d        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             2 minutes ago       Up 2 minutes        8000/tcp            whoami.4.0lg12zndbal72exqe08r9wvpg
8db1657e8517        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             2 minutes ago       Up 2 minutes        8000/tcp            whoami.5.5z6mvsrdy73m5w24icgsqc8i2
1b6df814c654        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             8 minutes ago       Up 8 minutes        8000/tcp            whoami.1.bg4qlpiye6h6uxyf8cmkwuh52
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see from the five containers that were started three reside on &amp;lsquo;pi6&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if we can find the rest:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi1 docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS               NAMES
db411a119c0a        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             6 minutes ago       Up 6 minutes        8000/tcp            whoami.2.2tf7yhmx9haol7e2b7xib2emj
0a4bf32fa9c4        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             6 minutes ago       Up 6 minutes        8000/tcp            whoami.3.2r6mm091c2ybr0f9jz4qaxw9k
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So what happens when I just leave the Swarm cluster on &amp;lsquo;pi1&amp;rsquo;?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi1 docker swarm leave
Node left the default swarm.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now I should be two containers short, right?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what we have on our remaining node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS               NAMES
58620e3d533c        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             46 seconds ago      Up 43 seconds       8000/tcp            whoami.2.cgc4e2ixulc2f3ehr4laoursg
acc9b523f434        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             46 seconds ago      Up 43 seconds       8000/tcp            whoami.3.67bhlo3nwgehthi3bg5bfdzue
e1863a2be88d        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             8 minutes ago       Up 8 minutes        8000/tcp            whoami.4.0lg12zndbal72exqe08r9wvpg
8db1657e8517        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             8 minutes ago       Up 8 minutes        8000/tcp            whoami.5.5z6mvsrdy73m5w24icgsqc8i2
1b6df814c654        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             15 minutes ago      Up 14 minutes       8000/tcp            whoami.1.bg4qlpiye6h6uxyf8cmkwuh52
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What we witnessed here is the same what would have happend if we just had a failing &amp;lsquo;pi1&amp;rsquo; node.
All the containers that were running on node &amp;lsquo;pi1&amp;rsquo; were migrated to the remaining cluster nodes automatically.
That&amp;rsquo;s pretty impressive.&lt;/p&gt;

&lt;p&gt;So to recap what we just did:&lt;br /&gt;
We created a small dynamic microservice applications with just the plain Docker.
Docker Swarm is now integrated into the Docker-Engine instead of being a separate piece of software.
In many cases this makes a separate proxy for the backend services of your application obsolete. No more nginx, HAProxy or Traefik. Sorry to see you go&amp;hellip;&lt;/p&gt;

&lt;p&gt;Despite having less moving parts we now have additional loadbalancing and high availability feature builtin.
I am really looking forward to find out what else there is in store with the new Docker Swarm and how it works together with Docker Compose.&lt;/p&gt;

&lt;p&gt;But that&amp;rsquo;s a story for another day&amp;hellip;&lt;/p&gt;

&lt;p&gt;As always use the comments below to give us feedback and share the news about this release on Twitter, Facebook or Google+.&lt;/p&gt;

&lt;p&gt;Govinda &lt;a href=&#34;https://twitter.com/_beagile_&#34;&gt;@_beagile__&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Microservices Bliss with Docker and Traefik</title>
      <link>http://blog.hypriot.com/post/microservices-bliss-with-docker-and-traefik/</link>
      <pubDate>Tue, 07 Jun 2016 09:15:00 +0000</pubDate>
      
      <guid>http://blog.hypriot.com/post/microservices-bliss-with-docker-and-traefik/</guid>
      <description>

&lt;p&gt;A couple of weeks ago I found this really nice and neat HTTP reverse proxy called &lt;a href=&#34;https://docs.traefik.io/&#34;&gt;Traefik&lt;/a&gt;.
It is meant to act as frontend proxy for microservices that are provided by a dynamic backend like Docker.&lt;/p&gt;

&lt;p&gt;Did you realize the important part of the last sentence was &lt;strong&gt;dynamic&lt;/strong&gt;?&lt;/p&gt;

&lt;p&gt;What makes Traefik really special is its ability of adding and removing container backend services by listening to Docker events.
So whenever a Docker container is started or stopped Traefik knows about it and adds the container to its list of active backend services.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/traefik/architecture.png&#34; alt=&#34;Traffic&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;With this ability Traefik can replace much more complicated setups based on Nginx or HAProxy that have to use additional tools like
&lt;a href=&#34;https://github.com/gliderlabs/registrator&#34;&gt;Registrator&lt;/a&gt;, &lt;a href=&#34;https://www.consul.io/&#34;&gt;Consul&lt;/a&gt; and &lt;a href=&#34;https://github.com/hashicorp/consul-template&#34;&gt;Consul-Template&lt;/a&gt; to achieve the same kind of functionality.&lt;/p&gt;

&lt;p&gt;So let me show you with a simple microservice example how easy it is to get started with Traefik&amp;hellip;&lt;/p&gt;

&lt;p&gt;As you can see in the following architecture overview we will have a simple HTTP service that answers incoming HTTP requests.&lt;/p&gt;

&lt;p&gt;We have multiple backend services that are running on different physical nodes for high availability and loadbalancing reasons.
Traefik serves as a frontend proxy that loadbalances incoming requests to the available backend services.&lt;/p&gt;

&lt;p&gt;Traefik as well as the backend services will run on top of a Docker Swarm cluster as containers.
In this example each backend service will answer with their individual container ID to make it easy to see which one answered.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/traefik/microsservice_example_end.jpg&#34; alt=&#34;Traffic&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;So to get started we need a running Docker Swarm Cluster first.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-docker-swarm-cluster:eaccea7a352d1344b842649dc78262ad&#34;&gt;Creating a Docker Swarm Cluster&lt;/h2&gt;

&lt;p&gt;One of fastest and easiest ways to get a Docker Swarm cluster running is to use our &lt;a href=&#34;https://github.com/hypriot/cluster-lab&#34;&gt;Hypriot Cluster Lab&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As the Cluster Lab comes already preinstalled with out latest HypriotOS &amp;ldquo;Barbossa&amp;rdquo; release for the Raspberr Pi I will show you how to set up a Swarm Cluster with that.&lt;/p&gt;

&lt;p&gt;To follow along you will need at least three Raspberry Pi&amp;rsquo;s. I will use my Pico-Cluster with five nodes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/traefik/picocluster.jpg&#34; alt=&#34;Traffic&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The first step is flashing the necessary SD card images with HypriotOS.&lt;/p&gt;

&lt;p&gt;Clone the Hypriot flash repository and change into the appropriate folder for the operating system you are using to flash the SD cards.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/hypriot/flash.gi://github.com/hypriot/flash.git
$ cd flash/Darwin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the flash tool ready we now can prepare the SD card for our &lt;strong&gt;leader node&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./flash --hostname cl-leader https://downloads.hypriot.com/hypriotos-rpi-v0.8.0.img.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Repeat the process for the &lt;strong&gt;follower nodes&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in {1..4} do; ./flash --hostname cl-follower${i} https://downloads.hypriot.com/hypriotos-rpi-v0.8.0.img.zip; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While the SD cards for the follower nodes are still being flashed you can already start the leader node.&lt;/p&gt;

&lt;p&gt;SSH into the leader and become root user:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh pirate@cl-leader.local
$ sudo su
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make the Cluster Lab work with Traefik we need to update to the most recent version:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apt-get update
$ apt-get install hypriot-cluster-lab=0.2.13-1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then start the Hypriot Cluster Lab with verbose output logging enabled:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ VERBOSE=true cluster-lab start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While the Cluster Lab starts you can see how it configures itself and does a number of self-tests.
If not all steps are green stop it and start it again. If that fails, too, have a look at our &lt;a href=&#34;https://github.com/hypriot/cluster-lab#troubleshooting&#34;&gt;troubleshooting section&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After the leader node is ready, it is time to boot the rest of our nodes and update and start the Cluster Lab in the same fashion.
So go ahead and come back when your are done.&lt;/p&gt;

&lt;p&gt;Allright, We can now check if we really have a healthy five nodes Swarm Cluster by executing the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOCKER_HOST=tcp://192.168.200.1:2378 docker info | grep Nodes
Nodes: 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And voila we now really have five nodes in our cluster.
Congrats!&lt;/p&gt;

&lt;p&gt;As you made it so far the rest will be a piece of a cake!&lt;/p&gt;

&lt;h3 id=&#34;setting-up-our-microservice-app-with-traefik:eaccea7a352d1344b842649dc78262ad&#34;&gt;Setting up our microservice app with Traefik&lt;/h3&gt;

&lt;p&gt;Our example microservice application consists of two parts. The Traefik frontend and the WhoAmI application backend.
For both parts I have prepared images for you that can be pulled from the Docker Hub.&lt;/p&gt;

&lt;p&gt;The Traefik image is called &lt;a href=&#34;https://hub.docker.com/r/hypriot/rpi-traefik/&#34;&gt;hypriot/rpi-traefik&lt;/a&gt; and the WhoAmI image is called &lt;a href=&#34;https://hub.docker.com/r/hypriot/rpi-whoami/&#34;&gt;hypriot/rpi-whoami&lt;/a&gt;.
The Dockerfiles for both images can be found on Github in the &lt;a href=&#34;https://github.com/hypriot&#34;&gt;related repositories&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Because both Dockerfiles are a fine example of how easy it is to create Docker images for Golang based software I will
show them here, too.&lt;/p&gt;

&lt;p&gt;Dockerfile for &amp;ldquo;rpi-traefik&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM hypriot/rpi-alpine-scratch
RUN apk update &amp;amp;&amp;amp;\
    apk upgrade &amp;amp;&amp;amp;\
    apk add ca-certificates &amp;amp;&amp;amp;\
    rm -rf /var/cache/apk/*
ADD https://github.com/containous/traefik/releases/download/v1.0.0-beta.771/traefik_linux-arm /traefik
RUN chmod +x /traefik
EXPOSE 80 8080
ENTRYPOINT [&amp;quot;/traefik&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we just add the Traefik binary on top of an Alpine linux image. The result is an image that is already quite small with about 41 MB.
It propably could be made even smaller by ensuring that the Traefik binary is compiled as a static binary and then putting it into an empty scratch image.&lt;/p&gt;

&lt;p&gt;You can see how this can be done with the next Dockerfile for the WhoAmI image:&lt;/p&gt;

&lt;p&gt;Dockerfile for &amp;ldquo;rpi-whoami&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM scratch

ADD http /http

ENV PORT 8000
EXPOSE 8000

CMD [&amp;quot;/http&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With about 3 MB the resulting image is really small.&lt;/p&gt;

&lt;p&gt;Well, now it is time to put this all together in a Docker Compose application.&lt;/p&gt;

&lt;p&gt;Clone the following repository on you cluster leader:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/hypriot/rpi-cluster-lab-demos
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When the cloning is finished change into the &amp;lsquo;traefik&amp;rsquo; folder and use Docker Compose to start our application on top of our little Docker Swarm cluster:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd rpi-cluster-lab-demos/traefik
$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose up -d
Creating network &amp;quot;traefik_default&amp;quot; with the default driver
Creating traefik_traefik_1
Creating traefik_whoami_1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this command Docker Compose should start two containers.
One Traefik container on our leader and one WhoAmi container on one of our follower nodes.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s check if that really happened:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker ps | grep &#39;traefik\|whoami&#39;
cba8d9a7d8f7        hypriot/rpi-whoami         &amp;quot;/http&amp;quot;                  About a minute ago   Up About a minute   8000/tcp                                                 cl-follower1/traefik_whoami_1
7dc2b48a24e2        hypriot/rpi-traefik        &amp;quot;/traefik --web --doc&amp;quot;   About a minute ago   Up About a minute   192.168.200.1:80-&amp;gt;80/tcp, 192.168.200.1:8080-&amp;gt;8080/tcp   cl-leader/traefik_traefik_1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks good. So let&amp;rsquo;s test our application by flinging some HTTP request towards our frontend:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in {1..5}; do curl -H Host:whoami.docker.localhost http://192.168.200.1; done
I&#39;am f72892c9187c
I&#39;am f72892c9187c
I&#39;am f72892c9187c
I&#39;am f72892c9187c
I&#39;am f72892c9187c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see it is always the same backend container which is responding and that&amp;rsquo;s just as it should be.&lt;/p&gt;

&lt;p&gt;Next we are going to increase the number of backend containers with the help of Docker Compose scale command.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose scale whoami=5
Creating and starting traefik_whoami_2 ... done
Creating and starting traefik_whoami_3 ... done
Creating and starting traefik_whoami_4 ... done
Creating and starting traefik_whoami_5 ... done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can watch as Docker Compose tells Docker Swarm to spin up more containers.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s verify again if we now have five backend containers running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in {1..5}; do curl -H Host:whoami.docker.localhost http://192.168.200.1; done
I&#39;m 5d829fecbdaa
I&#39;m 5eb115353885
I&#39;m e0313ac24554
I&#39;m 642b5d2c8d09
I&#39;m f72892c9187c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect. Obviously Traefik did recognise that we started more containers and made them available to the frontend automatically.&lt;/p&gt;

&lt;p&gt;We can see what happened by looking at the logs of the Traefik container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose logs traefik
...
traefik_1  | time=&amp;quot;2016-06-07T06:50:38Z&amp;quot; level=debug msg=&amp;quot;Configuration received from provider docker: {\&amp;quot;backends\&amp;quot;:{\&amp;quot;backend-whoami\&amp;quot;:{\&amp;quot;servers\&amp;quot;:{\&amp;quot;server-traefik_whoami_1\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.3:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_2\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.5:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_3\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.6:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_4\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.4:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_5\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.7:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1}}}},\&amp;quot;frontends\&amp;quot;:{\&amp;quot;frontend-Host-whoami-docker-localhost\&amp;quot;:{\&amp;quot;backend\&amp;quot;:\&amp;quot;backend-whoami\&amp;quot;,\&amp;quot;routes\&amp;quot;:{\&amp;quot;route-frontend-Host-whoami-docker-localhost\&amp;quot;:{\&amp;quot;rule\&amp;quot;:\&amp;quot;Host:whoami.docker.localhost\&amp;quot;}},\&amp;quot;passHostHeader\&amp;quot;:true}}}&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:38Z&amp;quot; level=debug msg=&amp;quot;Last docker config received less than 2s, waiting...&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Waited for docker config, OK&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating frontend frontend-Host-whoami-docker-localhost&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Wiring frontend frontend-Host-whoami-docker-localhost to entryPoint http&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating route route-frontend-Host-whoami-docker-localhost Host:whoami.docker.localhost&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating backend backend-whoami&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating load-balancer wrr&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_4 at http://10.0.0.4:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_3 at http://10.0.0.6:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_2 at http://10.0.0.5:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_1 at http://10.0.0.3:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_5 at http://10.0.0.7:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=info msg=&amp;quot;Server configuration reloaded on :80&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looking at the logs we can now clearly see how Traefik catched the Docker event and how it reacted.&lt;/p&gt;

&lt;p&gt;Isnt&amp;rsquo; awesome?&lt;/p&gt;

&lt;p&gt;OK. So this was basically our quick tour on how to do set up a simple microservice example with Docker and Traefik.&lt;/p&gt;

&lt;p&gt;The only thing that is left for us now is to clean up again.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose down -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Did you notice the &amp;lsquo;-v&amp;rsquo; option? This seems to be really important as it cleans up all the containers including the overlay network that was created for us.
Without the &amp;lsquo;-v&amp;rsquo; option we would get an error the next time we start the application again with Docker Compose.&lt;/p&gt;

&lt;p&gt;It is also a good idea to stop the Cluster Lab on all nodes before you switch of your Raspberry Pi&amp;rsquo;s.&lt;/p&gt;

&lt;p&gt;So do a&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cluster-lab stop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;on all your cluster nodes.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s just amazing how many interesting technologies we used in this small blog post.
And it wasn&amp;rsquo;t to hard to get them running together, wasn&amp;rsquo;t it?&lt;/p&gt;

&lt;p&gt;That is mostly due to the work the &lt;a href=&#34;https://github.com/hypriot/cluster-lab&#34;&gt;Hypriot Cluster Lab&lt;/a&gt; does for us and of course under the hood it is the Docker-Engine, Docker-Swarm and Docker-Compose that let&amp;rsquo;s us do so much with so little effort.&lt;/p&gt;

&lt;p&gt;So make sure to give our Hypriot Cluster Lab a spin and try some of the examples in our &lt;a href=&#34;https://github.com/hypriot/rpi-cluster-lab-demos&#34;&gt;Hypriot Cluster Lab Demos&lt;/a&gt; repository or add some of your own. Pull requests are always welcome.&lt;/p&gt;

&lt;p&gt;As always use the comments below to give us feedback and share the news about this release on Twitter, Facebook or Google+.&lt;/p&gt;

&lt;p&gt;Govinda &lt;a href=&#34;https://twitter.com/_beagile_&#34;&gt;@_beagile__&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Hypriot Cluster Lab: Docker clustering as easy as it gets</title>
      <link>http://blog.hypriot.com/post/introducing-hypriot-cluster-lab-docker-clustering-as-easy-as-it-gets/</link>
      <pubDate>Tue, 08 Dec 2015 15:30:00 +0200</pubDate>
      
      <guid>http://blog.hypriot.com/post/introducing-hypriot-cluster-lab-docker-clustering-as-easy-as-it-gets/</guid>
      <description>

&lt;p&gt;Today we wanna share something with you that we have been working on for the last couple of weeks. And we are pretty exited about it, too.
It is based on our beloved &lt;a href=&#34;http://blog.hypriot.com/post/get-your-all-in-one-docker-playground-now-hypriotos-reloaded/&#34;&gt;HypriotOS&lt;/a&gt; and makes it dead simple to build Docker clusters.&lt;/p&gt;

&lt;p&gt;Until now it was not exactly easy to get started with Docker clustering.
You would have needed specific knowledge and lots of time to manually configure the cluster and its individual nodes.&lt;/p&gt;

&lt;p&gt;Well, that&amp;rsquo;s now a thing of the past.&lt;/p&gt;

&lt;p&gt;May we introduce to you the newest member of the Hypriot family: &lt;strong&gt;The Hypriot Cluster Lab!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/cluster-lab-release-v01/cluster_lab.png&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;With the &lt;strong&gt;Hypriot Cluster Lab&lt;/strong&gt; it is just a matter of minutes to set up your own personal Docker cluster.
All you need is a couple of Raspberry Pi&amp;rsquo;s - 3, 5, 30 or even 100 - it is up to you - and our Hypriot Cluster Lab SD card image.&lt;/p&gt;

&lt;p&gt;We designed the Cluster Lab to be completely self-configuring, so there is nothing to configure or to set up.
Basically you just need to download our Cluster Lab SD card image and flash it onto a number of SD cards.
Then ensure that all your Pi&amp;rsquo;s have network connectivity, insert the SD cards and switch on power.
Everything else is taken care of automatically by our Cluster Lab.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Docker Clustering as easy as it gets!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When we started out to develop the Cluster Lab we wanted to be able to create complex Raspberry Pi based clusters with an arbitrary number of nodes.
We wanted to directly jump to deploying all kind of interesting services on top of the cluster instead of being concerned with setting up the cluster itself.&lt;/p&gt;

&lt;p&gt;And well - we managed to pull this off by combining a number of great technologies.
For instance &lt;strong&gt;Avahi&lt;/strong&gt; for announcing/managing who is a master and who is a slave node in the cluster. &lt;strong&gt;VLAN&lt;/strong&gt; for isolating the cluster network from other existing networks.
&lt;strong&gt;DHCP&lt;/strong&gt; for automatically assigning IP addresses to slave nodes in the cluster network. &lt;strong&gt;Consul&lt;/strong&gt; as a service registry and key-value-store.
And of course a number of other Docker related technologies that we already provide in HypriotOS: &lt;strong&gt;Docker Engine&lt;/strong&gt;, &lt;strong&gt;Swarm&lt;/strong&gt; and &lt;strong&gt;Compose&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;These technologies work together seamlessly and form what we call the Hypriot Cluster Lab. On top of it we are now able to easily deploy all kind of cluster services.
We have a number of ideas where this can come in handy in the future! Think Kubernetes for instance or Redis cluster.&lt;/p&gt;

&lt;p&gt;The Cluster Lab is still a bit rough around the edges and is more technology preview than production ready software, but we think it demonstrates the basic use case very well and shows the potential.
So for the coming weeks we want to gather feedback and make it more polished and resilient.
After that our main goal is to make it possible that all kind of cluster scenarios can be deployed on top of the Cluster Lab with just one command.
We want to make this possible by providing a kind of plugin-mechanism so that the community can help us in enabling many more interesting cluster use cases.&lt;/p&gt;

&lt;p&gt;The main reason that makes us really excited about the Cluster Lab, is that we think that there is great potential in using it as an educational tool in schools, universities or in commercial trainings.
It can be used to teach about Linux, Networking, Clustering, Microservices and so much more!&lt;/p&gt;

&lt;p&gt;And with the latest member of the Raspberry Pi family - the &lt;a href=&#34;http://swag.raspberrypi.org/collections/pi-zero/products/pi-zero&#34;&gt;Pi Zero&lt;/a&gt; - it got really cheap to have your own cluster. For about 50 bucks you are able to have a two to three node physical cluster.
And believe us - having physical nodes and being able to pull the network or power to simulate different cluster scenarios makes all the difference.
Working with &lt;strong&gt;real hardware&lt;/strong&gt; compared to a virtual environment (e.g. Vagrant) &lt;strong&gt;has a certain raw and primal feel about it&lt;/strong&gt; that we really like. :)&lt;/p&gt;

&lt;p&gt;So enough talking - let&amp;rsquo;s get our hands dirty - shall we?&lt;/p&gt;

&lt;h3 id=&#34;prerequisites-or-what-you-gonna-need-to-follow-along:8280d5ff2f6dfae78180ad5a72400c1a&#34;&gt;Prerequisites or what you gonna need to follow along&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;at least two &lt;strong&gt;Raspberry Pi&amp;rsquo;s&lt;/strong&gt;: Model 1 or 2 - both will do&lt;/li&gt;
&lt;li&gt;for each Raspberry Pi a &lt;strong&gt;power supply&lt;/strong&gt;, a &lt;strong&gt;MicroSD card&lt;/strong&gt; and a &lt;strong&gt;network cable&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;a &lt;strong&gt;network switch&lt;/strong&gt; that is somehow connected to the Internet and a DHCP server; both is usually provided by your typical off-the-shelf home router&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Additionally, the switch should not filter IEEE 802.1Q VLAN flags out of network packets. Usually this feature is provided even by cheap switches. If you wanna be safe, go through a small test to figure this out. The test is &lt;a href=&#34;https://github.com/hypriot/cluster-lab/blob/master/README.md#troubleshooting&#34;&gt;listed here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;download-flash-boot-enjoy:8280d5ff2f6dfae78180ad5a72400c1a&#34;&gt;Download. Flash. Boot. Enjoy!&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;Download&lt;/strong&gt; the &lt;a href=&#34;http://downloads.hypriot.com/hypriot_20160121-235123_clusterlab.img.zip&#34;&gt;Hypriot Cluster Lab SD card image&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; Flash the image to your SD cards your way or use &lt;a href=&#34;https://github.com/hypriot/flash&#34;&gt;our funky flash script&lt;/a&gt; which makes flashing the SD cards so much easier.&lt;/p&gt;

&lt;p&gt;Another advantage of our flash script is that it also allows you to give your cluster nodes unique hostnames:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ flash --hostname cl-master http://downloads.hypriot.com/hypriot_20160121-235123_clusterlab.img.zip
$ flash --hostname cl-node-1 http://downloads.hypriot.com/hypriot_20160121-235123_clusterlab.img.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; Put the freshly flashed SD cards in each node&amp;rsquo;s SD card slot.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.&lt;/strong&gt; Power on &lt;strong&gt;only one&lt;/strong&gt; node. This node will automatically become the master node of the cluster. It might take up to two minutes until the master node is fully functional.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.&lt;/strong&gt; Find out the IP address of your master node. One way to do this is via &lt;a href=&#34;https://nmap.org/&#34;&gt;nmap&lt;/a&gt; and is described &lt;a href=&#34;http://blog.hypriot.com/getting-started-with-docker-and-linux-on-the-raspberry-pi/#ensure-everything-works:8814904f208dcaade82991443c7514e0&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6.&lt;/strong&gt; Use the IP (from step 5) or the hostname (from step 2) to point your browser to &lt;code&gt;http://{IP or hostname of the master node}:8500&lt;/code&gt;. In our case &lt;code&gt;http://cl-master:8500&lt;/code&gt; opens the Consul web interface and our cluster master node is displayed:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/cluster-lab-release-v01/consul_cl_master.png&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7.&lt;/strong&gt; Power on all the remaining cluster nodes only if step 5 was successful. After about 2 minutes you should see the rest of them being listed in the Consul web interface, too.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/cluster-lab-release-v01/consul_cl_master_and_nodes.png&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;The last step makes the cluster fully operational and we are now able to work with the cluster in earnest.&lt;/p&gt;

&lt;h3 id=&#34;babysteps-with-our-cluster-lab:8280d5ff2f6dfae78180ad5a72400c1a&#34;&gt;Babysteps with our Cluster Lab&lt;/h3&gt;

&lt;p&gt;Congratulations, you got your Hypriot Cluster Lab up and running! That was easy, wasn&amp;rsquo;t it?&lt;/p&gt;

&lt;p&gt;The Cluster Lab is using &lt;a href=&#34;https://docs.docker.com/swarm/&#34;&gt;Docker Swarm&lt;/a&gt; for managing Docker containers on the nodes that make up the cluster.
Docker Swarm will distribute containers based on different distribution &lt;a href=&#34;https://docs.docker.com/swarm/scheduler/strategy/&#34;&gt;strategies&lt;/a&gt; to individual nodes.
Per default Docker Swarm uses the &lt;em&gt;spread&lt;/em&gt; strategy to evenly distribute container on cluster nodes.&lt;/p&gt;

&lt;p&gt;Working with Docker Swarm is easy. To start we first need to log into our cluster master:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh root@cl-master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There we can use the Docker Client to connect to the Swarm Manager instance. We do that by providing the &amp;lsquo;-H&amp;rsquo; flag to the &lt;code&gt;docker&lt;/code&gt; command.
This enables the Docker client to use the Docker Remote API for accessing the Swarm Manager.&lt;/p&gt;

&lt;p&gt;To display some basic info about the Swarm Cluster run&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H cl-master:2378 info
Containers: 7
Images: 6
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 3
 cl-master: 192.168.200.1:2375
  └ Containers: 3
  └ Reserved CPUs: 0 / 4
  └ Reserved Memory: 0 B / 971.8 MiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.12-hypriotos-v7+, operatingsystem=Raspbian GNU/Linux 8 (jessie), storagedriver=overlay
 cl-node-1: 192.168.200.115:2375
  └ Containers: 2
  └ Reserved CPUs: 0 / 4
  └ Reserved Memory: 0 B / 971.8 MiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.12-hypriotos-v7+, operatingsystem=Raspbian GNU/Linux 8 (jessie), storagedriver=overlay
 cl-node-2: 192.168.200.113:2375
  └ Containers: 2
  └ Reserved CPUs: 0 / 4
  └ Reserved Memory: 0 B / 971.8 MiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.12-hypriotos-v7+, operatingsystem=Raspbian GNU/Linux 8 (jessie), storagedriver=overlay
CPUs: 12
Total Memory: 2.84
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Instead of the hostname &lt;code&gt;cl-master&lt;/code&gt; one can also use the IP address that is always fixed for the cluster master node: 192.168.200.1.&lt;/p&gt;

&lt;p&gt;Ok - it seems our Swarm cluster is truly up and running.&lt;/p&gt;

&lt;p&gt;Time to get a little bit more daring.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s spin up a web interface for managing our nodes called &lt;a href=&#34;https://github.com/crosbymichael/dockerui&#34;&gt;DockerUI&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker -H cl-master:2378 run -d -p 9000:9000 --env=&amp;quot;constraint:node==cl-master&amp;quot; --name dockerui hypriot/rpi-dockerui -e http://192.168.200.1:2378
51f2eb09ab48540eb4a052bbe07644487c3a0b29ca44a6217ea6aebf17b3df0c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The most interesting part here is the env parameter &lt;code&gt;--env=&amp;quot;constraint:node==cl-master&amp;quot;&lt;/code&gt; which tells the Swarm Manager that we want to start our new container on the &lt;strong&gt;cl-master&lt;/strong&gt; node.
Without that the new container would be started by Docker Swarm on one of the nodes according to the &lt;em&gt;spread&lt;/em&gt; strategy.
By using the &amp;lsquo;constraint:node&amp;rsquo; label we are able to control on which node a container gets started.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s open the DockerUI with the following URL: &lt;code&gt;http://cl-master:9000&lt;/code&gt;.
If everything did work you should now see an overview of your running containers similar to this one:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.hypriot.com/images/cluster-lab-release-v01/dockerui.png&#34; alt=&#34;&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Back to the command line we can see the same result by using the &lt;code&gt;docker ps&lt;/code&gt; command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H cl-master:2378 ps
CONTAINER ID        IMAGE                                                              COMMAND                  CREATED             STATUS              PORTS                          NAMES
51f2eb09ab48        hypriot/rpi-dockerui                                               &amp;quot;./dockerui -e http:/&amp;quot;   12 minutes ago      Up 12 minutes       192.168.200.1:9000-&amp;gt;9000/tcp   cl-master/dockerui
fca75c6b759a        hypriot/rpi-consul                                                 &amp;quot;/consul agent -serve&amp;quot;   About an hour ago   Up About an hour                                   cl-node-2/bin_consul_1
4bfa58ed2a07        hypriot/rpi-swarm                                                  &amp;quot;/swarm join --advert&amp;quot;   About an hour ago   Up About an hour    2375/tcp                       cl-node-2/bin_swarm_1
ec61f8f5d766        hypriot/rpi-consul                                                 &amp;quot;/consul agent -serve&amp;quot;   About an hour ago   Up About an hour                                   cl-node-1/bin_consul_1
75c7cb003639        0104b3a10aad7e9a3d38ca4dce652c73d195b87171675c7dbc114ae85a444831   &amp;quot;/swarm join --advert&amp;quot;   About an hour ago   Up About an hour    2375/tcp                       cl-node-1/bin_swarm_1
df027cd23e69        hypriot/rpi-swarm                                                  &amp;quot;/swarm manage consul&amp;quot;   2 hours ago         Up 2 hours          192.168.200.1:2378-&amp;gt;2375/tcp   cl-master/bin_swarmmanage_1
f6b11e9e4f07        hypriot/rpi-consul                                                 &amp;quot;/consul agent -serve&amp;quot;   2 hours ago         Up 2 hours                                         cl-master/bin_consul_1
8658010a4433        hypriot/rpi-swarm                                                  &amp;quot;/swarm join --advert&amp;quot;   2 hours ago         Up 2 hours          2375/tcp                       cl-master/bin_swarm_1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By now you should have gotten the hang of it and come to expect that you can use many of the Docker command line commands with Swarm, too.
And you are right - you just need to remember to use the &lt;code&gt;-H&lt;/code&gt; flag as part of the Docker command.&lt;/p&gt;

&lt;h3 id=&#34;getting-to-the-grown-up-stuff:8280d5ff2f6dfae78180ad5a72400c1a&#34;&gt;Getting to the grown-up stuff&lt;/h3&gt;

&lt;p&gt;After we did our first babysteps successfully it is now time for some serious grown-up stuff.
Certainly Docker multi-host networking can be considered serious stuff - don&amp;rsquo;t you think?&lt;/p&gt;

&lt;p&gt;First let&amp;rsquo;s see if we already have any networks:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H cl-master:2378 network ls
NETWORK ID          NAME                DRIVER
d88253054dd4        cl-node-1/none      null
e78f9fc77a31        cl-node-2/bridge    bridge
12d2cb0e387d        cl-node-2/none      null
020bdb74ea43        cl-node-1/host      host
b39702828ebf        cl-node-1/bridge    bridge
c24764cf7077        cl-master/host      host
480319fbca22        cl-node-2/host      host
e5d7f7a69313        cl-master/bridge    bridge
7153745ef548        cl-master/none      null
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These are the networks that are already present by default.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s add our own overlay network:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H cl-master:2378 network create -d overlay my-net
54583b74b0c5b678678db18b99a1148049640e3c4e6ac6f5cdfa0938b1399f3a
HypriotOS: root@cl-master in ~
$ docker -H cl-master:2378 network ls
NETWORK ID          NAME                DRIVER
7153745ef548        cl-master/none      null
c24764cf7077        cl-master/host      host
54583b74b0c5        my-net              overlay
480319fbca22        cl-node-2/host      host
e5d7f7a69313        cl-master/bridge    bridge
b39702828ebf        cl-node-1/bridge    bridge
d88253054dd4        cl-node-1/none      null
e78f9fc77a31        cl-node-2/bridge    bridge
12d2cb0e387d        cl-node-2/none      null
020bdb74ea43        cl-node-1/host      host
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see we now have successfully created our first Docker multi-node overlay network.
This overlay network is really useful. Any container started in this network can talk to any other container in the network by default.&lt;/p&gt;

&lt;p&gt;In order to see how this works we are going to start two containers on different cluster nodes that will talk to each other.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H cl-master:2378 run -itd --name=webserver --net=my-net --env=&amp;quot;constraint:node==cl-node-1&amp;quot; hypriot/rpi-nano-httpd
378ddbe05781360f57f869f9aec7ad4c2cd703047cb5da11a9a7f395501bc533
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Listing the running containers in our cluster we now have:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H cl-master:2378 ps
CONTAINER ID        IMAGE                                                              COMMAND                  CREATED             STATUS              PORTS                          NAMES
378ddbe05781        hypriot/rpi-nano-httpd                                             &amp;quot;/httpd 80&amp;quot;              26 seconds ago      Up 23 seconds       80/tcp                         cl-node-1/webserver
51f2eb09ab48        hypriot/rpi-dockerui                                               &amp;quot;./dockerui -e http:/&amp;quot;   41 minutes ago      Up 40 minutes       192.168.200.1:9000-&amp;gt;9000/tcp   cl-master/dockerui
fca75c6b759a        hypriot/rpi-consul                                                 &amp;quot;/consul agent -serve&amp;quot;   About an hour ago   Up About an hour                                   cl-node-2/bin_consul_1
4bfa58ed2a07        hypriot/rpi-swarm                                                  &amp;quot;/swarm join --advert&amp;quot;   About an hour ago   Up About an hour    2375/tcp                       cl-node-2/bin_swarm_1
ec61f8f5d766        hypriot/rpi-consul                                                 &amp;quot;/consul agent -serve&amp;quot;   About an hour ago   Up About an hour                                   cl-node-1/bin_consul_1
75c7cb003639        0104b3a10aad7e9a3d38ca4dce652c73d195b87171675c7dbc114ae85a444831   &amp;quot;/swarm join --advert&amp;quot;   2 hours ago         Up 2 hours          2375/tcp                       cl-node-1/bin_swarm_1
df027cd23e69        hypriot/rpi-swarm                                                  &amp;quot;/swarm manage consul&amp;quot;   3 hours ago         Up 3 hours          192.168.200.1:2378-&amp;gt;2375/tcp   cl-master/bin_swarmmanage_1
f6b11e9e4f07        hypriot/rpi-consul                                                 &amp;quot;/consul agent -serve&amp;quot;   3 hours ago         Up 3 hours                                         cl-master/bin_consul_1
8658010a4433        hypriot/rpi-swarm                                                  &amp;quot;/swarm join --advert&amp;quot;   3 hours ago         Up 3 hours          2375/tcp                       cl-master/bin_swarm_1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Everything so far looks good. So let&amp;rsquo;s get the final piece working by starting a web client that talks to our webserver.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker -H cl-master:2378 run -it --rm --net=my-net --env=&amp;quot;constraint:node==cl-node-2&amp;quot; hypriot/armhf-busybox wget -O- http://webserver/index.html
Connecting to webserver (10.0.0.2:80)
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;Pi armed with Docker by Hypriot&amp;lt;/title&amp;gt;
  &amp;lt;body style=&amp;quot;width: 100%; background-color: black;&amp;quot;&amp;gt;
    &amp;lt;div id=&amp;quot;main&amp;quot; style=&amp;quot;margin: 100px auto 0 auto; width: 800px;&amp;quot;&amp;gt;
      &amp;lt;img src=&amp;quot;pi_armed_with_docker.jpg&amp;quot; alt=&amp;quot;pi armed with docker&amp;quot; style=&amp;quot;width: 800px&amp;quot;&amp;gt;
    &amp;lt;/div&amp;gt;
  &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
-                    100% |*******************************|   304   0:00:00 ETA
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see we have been able to spin up a busybox container on another node.
We used it to fetch the index.html page with the &lt;code&gt;wget&lt;/code&gt; command from our webserver container.&lt;/p&gt;

&lt;p&gt;The simplicity of this illustrates how powerful Docker networking has become.
Creating this kind of a setup with - for example &lt;a href=&#34;http://openvswitch.org/&#34;&gt;OpenVSwitch&lt;/a&gt; - was way more complicated in the past.&lt;/p&gt;

&lt;p&gt;It is possible to create far more complex scenarios with our Cluster Lab, but hopefully we were able to demonstrate a bit of the potential it has.
We will write more about those in some future blog posts.&lt;/p&gt;

&lt;p&gt;Until then we hope that it was fun to follow along and that we could infect you a little bit with our passion for Docker clustering.&lt;/p&gt;

&lt;p&gt;You can find the source code of the Hypriot Cluster Lab at &lt;a href=&#34;https://github.com/hypriot/cluster-lab&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As always, use the comments below to give us feedback, discuss this post on &lt;a href=&#34;https://news.ycombinator.com/item?id=10696752&#34;&gt;HackerNews&lt;/a&gt; and share this post on Twitter, Google or Facebook.&lt;/p&gt;

&lt;p&gt;Andreas &amp;amp; Mathias&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>