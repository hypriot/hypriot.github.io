<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker Swarm on Docker Pirates ARMed with explosive stuff</title>
    <link>https://blog.hypriot.com/tags/docker-swarm/index.xml</link>
    <description>Recent content in Docker Swarm on Docker Pirates ARMed with explosive stuff</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://blog.hypriot.com/tags/docker-swarm/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Swarm Machines or Having fun with Docker Machine and the new Docker Swarm orchestration</title>
      <link>https://blog.hypriot.com/post/swarm-machines-or-having-fun-with-docker-machine-and-the-new-docker-swarm-orchestration/</link>
      <pubDate>Tue, 21 Jun 2016 13:49:00 +0200</pubDate>
      
      <guid>https://blog.hypriot.com/post/swarm-machines-or-having-fun-with-docker-machine-and-the-new-docker-swarm-orchestration/</guid>
      <description>&lt;p&gt;In the last couple of days there were some users on our Gitter channel having problems accessing their Raspberry Pi&amp;rsquo;s with HypriotOS via Docker Machine.
As we have not yet written how that works I thought I would do a short blog post on how to use Docker Machine with HypriotOS.&lt;/p&gt;

&lt;p&gt;But that&amp;rsquo;s not all. Yesterday when I watched the DockerCon Keynote Livestream of the new Docker orchestration I wondered how Docker Machine and the new orchestration would work together.&lt;/p&gt;

&lt;p&gt;So just for the fun of it I decided I will explore that a bit, too.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/docker-machine/swarm_machines.jpg&#34; alt=&#34;Docker Swarm&#34; /&gt;
&lt;div style=&#34;text-align:right; font-size: smaller&#34;&gt;Image courtesy of &lt;a href=&#34;https://www.flickr.com/photos/thewakingdragon/&#34;&gt;Brent M&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;I am using the latest Docker4Mac with Docker on my notebook and three Raspberry Pi&amp;rsquo;s with HypriotOS 0.8 as hosts for my remote Docker Engines.&lt;/p&gt;

&lt;p&gt;The Docker version on the notebook and on the Pi&amp;rsquo;s is 1.12 RC1. Having the lastest Docker 1.12 is not necessary for the part about Docker Machine, but it is for the part about the new Docker orchestration.&lt;/p&gt;

&lt;h2 id=&#34;docker-machine&#34;&gt;Docker Machine&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/machine/&#34;&gt;Docker Machine&lt;/a&gt; is used to control remote Docker-Engines as if they were locally installed.&lt;/p&gt;

&lt;p&gt;That is very convenient in many cases, for instance if you have set up a Docker host with the help of Amazon AWS or Microsoft Azure and you can access it only remotely.
In that case you do not have to establish a SSH connection first in order to work with a specific Docker Engine.&lt;/p&gt;

&lt;p&gt;But that&amp;rsquo;s not all - Docker Machine also helps if there is no Docker-Engine present on a remote host.&lt;/p&gt;

&lt;p&gt;With the help of Docker Machine it is very easy to install and configure a new Docker Engine.&lt;/p&gt;

&lt;p&gt;Both in case of an existing or a new Docker Engine Docker Machine reconfigures the Engine to make it availabe via a HTTP network socket.
To ensure that only authorized clients can connect to the remote Docker Engine Docker Machine also sets up everything that is needed for &lt;a href=&#34;https://docs.docker.com/engine/security/https/&#34;&gt;securing the communication with TLS&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To remotely manage my Pi&amp;rsquo;s with Docker Machine I first need to copy my SSH public key to the remote host.
If you do not have a SSH key pair you need to &lt;a href=&#34;https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/#generating-a-new-ssh-key&#34;&gt;generate one first&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Transfering your public key to a remote host is easily done with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh-copy-id pirate@pi3.local
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command configures the remote host &amp;lsquo;pi3.local&amp;rsquo; in a way that I can access this host via SSH with my default SSH key (~/.ssh/id_rsa).&lt;/p&gt;

&lt;p&gt;We can test this now by executing:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh pirate@pi3.local ls -lah
total 32K
drwxr-xr-x 3 pirate pirate 4.0K Jun 21 12:01 .
drwxr-xr-x 3 root   root   4.0K May 17 22:43 ..
-rw------- 1 pirate pirate  116 Jun 21 12:01 .bash_history
-rw-r--r-- 1 pirate pirate  220 Oct 18  2014 .bash_logout
-rw-r--r-- 1 pirate pirate 2.5K May 17 22:42 .bash_prompt
-rw-r--r-- 1 pirate pirate  570 May 17 22:42 .bashrc
-rw-r--r-- 1 pirate pirate  314 May 17 22:42 .profile
drwx------ 2 pirate pirate 4.0K Jun 21 12:09 .ssh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command establishes a SSH connection to the host &amp;lsquo;pi3.local&amp;rsquo; and executes &amp;lsquo;ls -lah&amp;rsquo;. If you can see a similar output everything is OK.&lt;/p&gt;

&lt;p&gt;Next we need to add our &amp;lsquo;pi3.local&amp;rsquo; host to the list of hosts that are managed by Docker Machine.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if we already have some existing hosts that are managed by Docker Machine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine ls
NAME   ACTIVE   DRIVER    STATE     URL                          SWARM   DOCKER        ERRORS
pi1    -        generic   Running   tcp://192.168.178.171:2376           v1.12.0-rc1
pi2    -        generic   Running   tcp://192.168.178.24:2376            v1.12.0-rc1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And indeed we have two hosts that are already managed by Docker Machine.&lt;/p&gt;

&lt;p&gt;Adding another one is easy:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create --driver generic --generic-ip-address=192.168.178.59 --generic-ssh-key=/Users/govindaf/.ssh/id_rsa --generic-ssh-user=pirate --engine-storage-driver=overlay pi3
Running pre-create checks...
Creating machine...
(pi3) Importing SSH key...
Waiting for machine to be running, this may take a few minutes...
Detecting operating system of created instance...
Waiting for SSH to be available...
Detecting the provisioner...
Provisioning with debian...
Copying certs to the local machine directory...
Copying certs to the remote machine...
Setting Docker configuration on the remote daemon...
Checking connection to Docker...
Docker is up and running!
To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine env pi3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output looks good. Let&amp;rsquo;s dissect this command a bit to understand what it does.&lt;/p&gt;

&lt;p&gt;We are using the &amp;lsquo;create&amp;rsquo; subcommand of Docker Machine to create a new host that is managed by Docker Machine.
We are also using the &amp;lsquo;generic&amp;rsquo; driver that allows us to communicate with our Raspberry Pi&amp;rsquo;s via SSH.&lt;/p&gt;

&lt;p&gt;For this we need to tell Docker Machine some SSH connection details like the IP address of our target host, the SSH user and the location of our private SSH key.&lt;/p&gt;

&lt;p&gt;The IP address of our Pi can be easily obtained by running&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ping -c1 pi3.local
PING pi3.local (192.168.178.59): 56 data bytes
64 bytes from 192.168.178.59: icmp_seq=0 ttl=64 time=1.926 ms

--- pi3.local ping statistics ---
1 packets transmitted, 1 packets received, 0.0% packet loss
round-trip min/avg/max/stddev = 1.926/1.926/1.926/0.000 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is important that we provide the absolute path to our private SSH key with the option &amp;lsquo;generic-ssh-key&amp;rsquo;. A relative path did not work for me.&lt;/p&gt;

&lt;p&gt;Furthermore we need to tell Docker Machine which user it should use for the SSH connection.
The default here is the &amp;lsquo;root&amp;rsquo; user. With HypriotOS we can only use an unprivileged user which is why we need to provide the &amp;lsquo;generic-ssh-user&amp;rsquo; option.&lt;/p&gt;

&lt;p&gt;Last but no least we need to tell Machine to use the &amp;lsquo;overlay&amp;rsquo; filesystem for the configuration of the Docker Engine which is the default with HypriotOS.
Without this option Docker Machine would try to use &amp;lsquo;aufs&amp;rsquo; which would fail miserably.&lt;/p&gt;

&lt;p&gt;Alright, let&amp;rsquo;s see if we now have a third host under our Machine control:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine ls
NAME   ACTIVE   DRIVER    STATE     URL                          SWARM   DOCKER        ERRORS
pi1    -        generic   Running   tcp://192.168.178.171:2376           v1.12.0-rc1
pi3    -        generic   Running   tcp://192.168.178.59:2376            v1.12.0-rc1
pi2    -        generic   Running   tcp://192.168.178.24:2376            v1.12.0-rc1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yeah - we do.&lt;/p&gt;

&lt;p&gt;Sometimes you might get SSH timeout errors when setting up another host with Docker-Machine.
If this is the case make sure you did not forget to set up your SSH public key with the remote host first.&lt;/p&gt;

&lt;p&gt;Sometimes when Docker Machine tries to add a new host it happens that it is stuck halfway with an error.
In those cases the best course of action is often to remove the host first and add it again later.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine rm pi3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s assume all went well and we now have a list of host under remote control. How do you work with those now?&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s were the Docker Machine &amp;lsquo;env&amp;rsquo; subcommand comes into play.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine env pi3
export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot;
export DOCKER_HOST=&amp;quot;tcp://192.168.178.59:2376&amp;quot;
export DOCKER_CERT_PATH=&amp;quot;/Users/govindaf/.docker/machine/machines/pi3&amp;quot;
export DOCKER_MACHINE_NAME=&amp;quot;pi3&amp;quot;
# Run this command to configure your shell:
# eval $(docker-machine env pi3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The env command outputs a bunch of environment variables that control to which Docker instance our local Docker binary is talking to.
Per default the &amp;lsquo;docker&amp;rsquo; command only talks to our local Docker Engine - for instance on our notebook - but by exporting those environment variables this changes fundamentally.&lt;/p&gt;

&lt;p&gt;The easiest way to export the necessary variables is by running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval $(docker-machine env pi3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now everything I do with the &amp;lsquo;docker&amp;rsquo; command runs against the Docker Engine of my &amp;lsquo;pi3&amp;rsquo; host.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s check if that is true:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker info
Containers: 0
 Running: 0
 Paused: 0
 Stopped: 0
Images: 27
Server Version: 1.12.0-rc1
Storage Driver: overlay
 Backing Filesystem: extfs
Logging Driver: json-file
Cgroup Driver: cgroupfs
Plugins:
 Volume: local
 Network: bridge null host overlay
Swarm: inactive
Runtimes: default
Default Runtime: default
Security Options:
Kernel Version: 4.4.10-hypriotos-v7+
Operating System: Raspbian GNU/Linux 8 (jessie)
OSType: linux
Architecture: armv7l
CPUs: 4
Total Memory: 925.4 MiB
Name: pi3
ID: 5DYT:MHTS:4JQK:KNGB:FYZI:EFG4:YIPZ:2WJR:VW5Y:KLPJ:WXCX:S3CG
Docker Root Dir: /var/lib/docker
Debug Mode (client): false
Debug Mode (server): false
Registry: https://index.docker.io/v1/
WARNING: No cpuset support
Labels:
 provider=generic
Insecure Registries:
 127.0.0.0/8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see with the &amp;lsquo;Name&amp;rsquo; attribute, we are really working on host &amp;lsquo;pi3&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;Changing to another host is also easy.&lt;/p&gt;

&lt;p&gt;Just repeat the command from above and replace the hostname with another:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval $(docker-machine env pi2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;docker-machine-and-docker-swarm-mode&#34;&gt;Docker Machine and Docker Swarm Mode&lt;/h2&gt;

&lt;p&gt;In the past Docker Machine allowed to set up a Docker Swarm cluster with a &lt;a href=&#34;https://docs.docker.com/machine/reference/create/&#34;&gt;number of options&lt;/a&gt; for the &amp;lsquo;create&amp;rsquo; subcommand.&lt;/p&gt;

&lt;p&gt;With Docker 1.12 we now how a much more powerful version of Swarm that is directly integrated into Docker.
This feature is called Docker Swarm Mode and you can find some inital documentation about it &lt;a href=&#34;https://docs.docker.com/engine/swarm/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I could not find any specifics on how to use it together with Docker Machine. So there might be better ways of how to deal with it than what I am going to show you now.&lt;/p&gt;

&lt;p&gt;Assuming we have three fresh hosts that are managed by Docker Machine, we need to tell Docker to initialize a new Swarm cluster first.&lt;/p&gt;

&lt;p&gt;We can execute the necessary command on any of our hosts.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval $(docker-machine env pi1)
$ docker swarm init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command create a Docker Swarm cluster with one node. This first node automatically becomes a Swarm Manager Node.&lt;/p&gt;

&lt;p&gt;The output of &amp;lsquo;docker info&amp;rsquo; shows us what role our current Docker Engine plays in regard to Swarm:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker info
...
Swarm: active
 NodeID: efyap0lxrttld19djs3ygtuac
 IsManager: Yes
 Managers: 1
 Nodes: 1
 CACertHash: sha256:9a29dafb3f6f600b64e8ec7a421fd6386f938de623a3a479ca56229b22a6b680
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is also another command that is able to show us which nodes are part of our Swarm cluster:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker node ls
ID                           NAME  MEMBERSHIP  STATUS  AVAILABILITY  MANAGER STATUS
efyap0lxrttld19djs3ygtuac *  pi1   Accepted    Ready   Active        Leader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OK. Time to add two more nodes.&lt;/p&gt;

&lt;p&gt;First we need to switch our Docker environment with Docker Machine. Afterwards we join the existing Swarm cluster with the next node.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval $(docker-machine env pi2)
$ docker swarm join pi1:2377
This node joined a Swarm as a worker.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks promising. Let&amp;rsquo;s see what our &amp;lsquo;docker node ls&amp;rsquo; command has to say:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker node ls
Error response from daemon: this node is not participating as a Swarm manager
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What&amp;rsquo;s that?&lt;/p&gt;

&lt;p&gt;Obviously we are only able to use the &amp;lsquo;node&amp;rsquo; subcommand from a Swarm Manager node and not from a Swarm Worker node.
So ignoring this for the moment let&amp;rsquo;s add the last node, too.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval $(docker-machine env pi3)
$ docker swarm join pi1:2377
This node joined a Swarm as a worker.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s switch back to our original Swarm Manager node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ eval $(docker-machine env pi1)
$ docker node ls
ID                           NAME  MEMBERSHIP  STATUS  AVAILABILITY  MANAGER STATUS
3cgg9qfo6nk77zisgrst1333n    pi2   Accepted    Ready   Active
6lezwd8vplgcdmxyhswbc1cvp    pi3   Accepted    Ready   Active
efyap0lxrttld19djs3ygtuac *  pi1   Accepted    Ready   Active        Leader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see we have sucessfully set up a Docker Swarm Cluster with three nodes.&lt;/p&gt;

&lt;p&gt;With the help of Docker Machine this was really easy and straightforward as we only had to switch our Docker environment to work on individual nodes.&lt;/p&gt;

&lt;p&gt;So as a last treat for you and to be able to show another screenshot let&amp;rsquo;s start a small webserver in our Swarm cluster:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker service create --name hypriot-httpd -p 8080:80 --replicas 6 hypriot/rpi-busybox-httpd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command creates a Docker Swarm service that consists of six running httpd containers that are spread equally across the three nodes of our Swarm cluster.&lt;/p&gt;

&lt;p&gt;Seeing is believing so let&amp;rsquo;s check this again by using the &amp;lsquo;docker service task&amp;rsquo; sub sub command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker service tasks hypriot-httpd
ID                         NAME             SERVICE        IMAGE                      LAST STATE         DESIRED STATE  NODE
14ywlwfix019b95oizce0hgd2  hypriot-httpd.1  hypriot-httpd  hypriot/rpi-busybox-httpd  Running 6 minutes  Running        pi1
60k55m336zq04rke696m848w1  hypriot-httpd.2  hypriot-httpd  hypriot/rpi-busybox-httpd  Running 6 minutes  Running        pi3
55sl8zwi1v8om3pvtb0zscf8d  hypriot-httpd.3  hypriot-httpd  hypriot/rpi-busybox-httpd  Running 6 minutes  Running        pi2
105gbhovh5p3zmwpqaeg3hprd  hypriot-httpd.4  hypriot-httpd  hypriot/rpi-busybox-httpd  Running 6 minutes  Running        pi3
8her9l13z78g9mjdrkovs9d46  hypriot-httpd.5  hypriot-httpd  hypriot/rpi-busybox-httpd  Running 6 minutes  Running        pi2
5xwwxuvbwsr7pmomg91cnf08y  hypriot-httpd.6  hypriot-httpd  hypriot/rpi-busybox-httpd  Running 6 minutes  Running        pi1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On a Mac we now can open the website that is served by this service with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ open http://$(docker-machine ip pi1):8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are then rewarded with this neat little website:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/docker-machine/hypriot-http.jpg&#34; alt=&#34;Docker Swarm&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hope this tour was fun and gave you a feeling for the power that comes with Docker Machine.&lt;/p&gt;

&lt;p&gt;As always use the comments below to give us feedback and share the news about this release on Twitter, Facebook or Google+.&lt;/p&gt;

&lt;p&gt;Govinda &lt;a href=&#34;https://twitter.com/_beagile_&#34;&gt;@_beagile__&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>More Microservices Bliss with Docker 1.12 and Swarm only</title>
      <link>https://blog.hypriot.com/post/more-microservice-bliss-with-docker-1-12/</link>
      <pubDate>Mon, 20 Jun 2016 21:49:00 +0200</pubDate>
      
      <guid>https://blog.hypriot.com/post/more-microservice-bliss-with-docker-1-12/</guid>
      <description>&lt;p&gt;A couple of days ago I wrote a &lt;a href=&#34;https://blog.hypriot.com/post/microservices-bliss-with-docker-and-traefik/&#34;&gt;blog post&lt;/a&gt; about how easy it is to get a microservice application up and running with Docker and a HTTP proxy called Traefik.
I explained how awesome Traefik is because it makes complex setups with HAProxy, Registrator, Consul, etc. a thing of the past.&lt;/p&gt;

&lt;p&gt;I really thought it couldn&amp;rsquo;t get much easier. Oh boy - was I wrong!&lt;/p&gt;

&lt;p&gt;Today as part of the Docker opening keynote Docker demostrated an evolution of Docker Swarm that simplifies this whole scenario even more.
It makes setting up a Docker Swarm Cluster a really simple and straigtforward task.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how this new thing works&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/more-microservices/swarm.jpg&#34; alt=&#34;Docker Swarm&#34; /&gt;
&lt;div style=&#34;text-align:right; font-size: smaller&#34;&gt;Image courtesy of &lt;a href=&#34;https://www.flickr.com/photos/thewakingdragon/&#34;&gt;Brent M&lt;/a&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;If you remember the example from my last post - it consisted of a microservice application made of a frontend and a couple of backend services.
The frontend was a Traefik HTTP proxy that routed the requests to the backend services.
And the backend for the sake of simplicity was just a simple Go-based HTTP webserver that returned the ID of the containers it was running within.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/traefik/microsservice_example_end.jpg&#34; alt=&#34;Traffic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The new Docker Swarm removes the need for a separate HTTP proxy in front of our application containers.
The architecture from above is now slimmed down considerably and looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/more-microservices/architecture_with_swarm.jpg&#34; alt=&#34;With Swarm&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Less moving parts - that is great!&lt;/p&gt;

&lt;p&gt;Still we get built-in loadbalancing to our backend services. We even can access those services from every node in our cluster.
Docker Swarm has a kind of built-in mesh routing integrated that takes care of routing requests to the appropriate backend containers.&lt;/p&gt;

&lt;p&gt;With all the new functionality one could assume that setting up a Docker Swarm cluster got even more complicated than before.
But to the contrary - it got much easier - and that by leaps and bounds.&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t believe me? Just follow along.&lt;/p&gt;

&lt;p&gt;As you might have guessed, we are doing this on Raspberry Pi cluster again.
I am using a homegrown version of Docker 1.12 that I installed on my Raspberry Pi.
Hopefully when Docker 1.12 is not a release candidate anymore we will have a version for you ready, too.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what we have:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker version
Client:
 Version:      1.12.0-rc1
 API version:  1.24
 Go version:   go1.6.2
 Git commit:   1f136c1-unsupported
 Built:        Wed Jun 15 15:35:51 2016
 OS/Arch:      linux/arm

Server:
 Version:      1.12.0-rc1
 API version:  1.24
 Go version:   go1.6.2
 Git commit:   1f136c1-unsupported
 Built:        Wed Jun 15 15:35:51 2016
 OS/Arch:      linux/arm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great. Docker 1.12 RC1 is ready. We should have everything we need to get started.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if we can find out if we have same new features hidden in our Docker CLI.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker
Usage: docker [OPTIONS] COMMAND [arg...]
       docker [ --help | -v | --version ]

A self-sufficient runtime for containers.
    ...
    service   Manage Docker services
    ...
    stats     Display a live stream of container(s) resource usage statistics
    ...
    swarm     Manage Docker Swarm
    ...
    update    Update configuration of one or more containers

Run &#39;docker COMMAND --help&#39; for more information on a command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I removed the lines of the command output that have not changed compared to the previous release. What remains though is still pretty interesting&amp;hellip;&lt;/p&gt;

&lt;p&gt;We now seem to have a &amp;lsquo;docker swarm&amp;rsquo; command.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what it is all about&amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker swarm

Usage:  docker swarm COMMAND

Manage Docker Swarm

Options:
      --help   Print usage

Commands:
  init        Initialize a Swarm.
  join        Join a Swarm as a node and/or manager.
  update      update the Swarm.
  leave       Leave a Swarm.
  inspect     Inspect the Swarm

Run &#39;docker swarm COMMAND --help&#39; for more information on a command.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So &amp;lsquo;Initialize a Swarm.&amp;rsquo; seems to be exactly what we want. Let&amp;rsquo;s start with this one.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker swarm init
Swarm initialized: current node (1njlvzi9rk2syv3xojw217o0g) is now a manager.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have a Swarm manger node running it is time to add some more nodes to the cluster.&lt;br /&gt;
And it is really simple as well.&lt;/p&gt;

&lt;p&gt;Just go to another node of your cluster and execute:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi1 $ docker swarm join pi6:2377
This node joined a Swarm as a worker.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this command we basically just tell new nodes that they should join the Swarm Manager node on which we created the inital Swarm cluster.
In the background Docker Swarm now does some work for us.&lt;/p&gt;

&lt;p&gt;For instance it sets up encrypted communication channels between the cluster nodes. We do not need to manage TLS certificates on our own.&lt;/p&gt;

&lt;p&gt;Everybody who knows how involved it could be to get a Docker Swarm cluster up running in the past should realize how easy it is now.&lt;/p&gt;

&lt;p&gt;Still we are not yet finished.&lt;/p&gt;

&lt;p&gt;A &amp;lsquo;docker info&amp;rsquo; on our Swarm Manager node reveals some interesting tidbits.
Again I removed the uninteresting parts for brevity.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker info
...
Swarm: active
 NodeID: 1njlvzi9rk2syv3xojw217o0g
 IsManager: Yes
 Managers: 1
 Nodes: 2
 CACertHash: sha256:de4e2bff3b63700aad01df97bbe0397f131aabed5fabb7732283f044472323fc
...
Kernel Version: 4.4.10-hypriotos-v7+
Operating System: Raspbian GNU/Linux 8 (jessie)
OSType: linux
Architecture: armv7l
CPUs: 4
Total Memory: 925.4 MiB
Name: pi6
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see we now have a new &amp;lsquo;Swarm&amp;rsquo; part in the &amp;lsquo;docker info&amp;rsquo; output.
It tells us that our current node is a Swarm Manager node and that the cluster is composed of two cluster nodes in total.&lt;/p&gt;

&lt;p&gt;On our second node it looks a bit different as it is not a Manager node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Swarm: active
 NodeID: 3fmwt4taurwxczr2icboojz8g
 IsManager: No
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Until now we just have an interesting, but still very empty Swarm cluster.
Let&amp;rsquo;s change that.&lt;/p&gt;

&lt;p&gt;Before we start let me introduce you to the concept of a service that is also new abstraction with Docker 1.12.
You might have seen a hint of it already in the output of the Docker command above.
Yes, it is the &amp;lsquo;docker service&amp;rsquo; command that I am talking about.
A Docker service is basically just a bit of software running in a container that offers its &amp;lsquo;service&amp;rsquo; to the outside world and runs on a Swarm cluster.&lt;/p&gt;

&lt;p&gt;Such a service can consist of just one container or of multiple containers.
In the latter case we get high availability and/or loadbalancing for our service out of the box.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s create such a service based on our &amp;lsquo;whoami&amp;rsquo; image from my last blog post.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service create --name whoami -p 80:8000 hypriot/rpi-whoami
buy0q65lw7nshm76kvy5imxk3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the help of the &amp;lsquo;docker swarm ls&amp;rsquo; command we can check the status of our new service.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service ls
ID            NAME    SCALE  IMAGE               COMMAND
buy0q65lw7ns  whoami  1      hypriot/rpi-whoami
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s check if we can request the index page from our whoami container by sending I http request via curl to the ip of eth0 network interface.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ curl http://192.168.178.24
I&#39;m 1b6df814c654
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And it is working. Awesome!&lt;/p&gt;

&lt;p&gt;Those who followed along with keen eyes will have noticed the &amp;lsquo;SCALE&amp;rsquo; part in the header line of the &amp;lsquo;docker swarm ls&amp;rsquo; command.
It seems as we can scale our service somehow.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service scale whoami=5
whoami scaled to 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;OK. Let&amp;rsquo;s check what we have now:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker service ls
ID            NAME    SCALE  IMAGE               COMMAND
buy0q65lw7ns  whoami  5      hypriot/rpi-whoami

root@pi6 $ for i in {1..5}; do curl http://192.168.178.24; done
I&#39;m 8db1657e8517
I&#39;m e1863a2be88d
I&#39;m 1b6df814c654
I&#39;m 8db1657e8517
I&#39;m e1863a2be88d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is pretty neat.&lt;/p&gt;

&lt;p&gt;But this is not just way more simple than the old Swarm, it also feels much more snappier and faster when executing commands.
And remember I am working on Raspberry Pi&amp;rsquo;s and not on a beefy server like you would propably work on.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how this looks from the perspective of an individual Docker engine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi6 $ docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS               NAMES
e1863a2be88d        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             2 minutes ago       Up 2 minutes        8000/tcp            whoami.4.0lg12zndbal72exqe08r9wvpg
8db1657e8517        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             2 minutes ago       Up 2 minutes        8000/tcp            whoami.5.5z6mvsrdy73m5w24icgsqc8i2
1b6df814c654        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             8 minutes ago       Up 8 minutes        8000/tcp            whoami.1.bg4qlpiye6h6uxyf8cmkwuh52
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see from the five containers that were started three reside on &amp;lsquo;pi6&amp;rsquo;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if we can find the rest:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi1 docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS               NAMES
db411a119c0a        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             6 minutes ago       Up 6 minutes        8000/tcp            whoami.2.2tf7yhmx9haol7e2b7xib2emj
0a4bf32fa9c4        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             6 minutes ago       Up 6 minutes        8000/tcp            whoami.3.2r6mm091c2ybr0f9jz4qaxw9k
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So what happens when I just leave the Swarm cluster on &amp;lsquo;pi1&amp;rsquo;?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@pi1 docker swarm leave
Node left the default swarm.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now I should be two containers short, right?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what we have on our remaining node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker ps
CONTAINER ID        IMAGE                       COMMAND             CREATED             STATUS              PORTS               NAMES
58620e3d533c        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             46 seconds ago      Up 43 seconds       8000/tcp            whoami.2.cgc4e2ixulc2f3ehr4laoursg
acc9b523f434        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             46 seconds ago      Up 43 seconds       8000/tcp            whoami.3.67bhlo3nwgehthi3bg5bfdzue
e1863a2be88d        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             8 minutes ago       Up 8 minutes        8000/tcp            whoami.4.0lg12zndbal72exqe08r9wvpg
8db1657e8517        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             8 minutes ago       Up 8 minutes        8000/tcp            whoami.5.5z6mvsrdy73m5w24icgsqc8i2
1b6df814c654        hypriot/rpi-whoami:latest   &amp;quot;/http&amp;quot;             15 minutes ago      Up 14 minutes       8000/tcp            whoami.1.bg4qlpiye6h6uxyf8cmkwuh52
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What we witnessed here is the same what would have happened if we just had a failing &amp;lsquo;pi1&amp;rsquo; node.
All the containers that were running on node &amp;lsquo;pi1&amp;rsquo; were migrated to the remaining cluster nodes automatically.
That&amp;rsquo;s pretty impressive.&lt;/p&gt;

&lt;p&gt;So to recap what we just did:&lt;br /&gt;
We created a small dynamic microservice applications with just the plain Docker.
Docker Swarm is now integrated into the Docker-Engine instead of being a separate piece of software.
In many cases this makes a separate proxy for the backend services of your application obsolete. No more nginx, HAProxy or Traefik. Sorry to see you go&amp;hellip;&lt;/p&gt;

&lt;p&gt;Despite having fewer moving parts we now have additional load balancing and high availability features built-in.
I am really looking forward to find out what else there is in store with the new Docker Swarm and how it works together with Docker Compose.&lt;/p&gt;

&lt;p&gt;But that&amp;rsquo;s a story for another day&amp;hellip;&lt;/p&gt;

&lt;p&gt;As always use the comments below to give us feedback and share the news about this release on Twitter, Facebook or Google+.&lt;/p&gt;

&lt;p&gt;Govinda &lt;a href=&#34;https://twitter.com/_beagile_&#34;&gt;@_beagile__&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Microservices Bliss with Docker and Traefik</title>
      <link>https://blog.hypriot.com/post/microservices-bliss-with-docker-and-traefik/</link>
      <pubDate>Tue, 07 Jun 2016 09:15:00 +0000</pubDate>
      
      <guid>https://blog.hypriot.com/post/microservices-bliss-with-docker-and-traefik/</guid>
      <description>&lt;p&gt;A couple of weeks ago I found this really nice and neat HTTP reverse proxy called &lt;a href=&#34;https://docs.traefik.io/&#34;&gt;Traefik&lt;/a&gt;.
It is meant to act as frontend proxy for microservices that are provided by a dynamic backend like Docker.&lt;/p&gt;

&lt;p&gt;Did you realize the important part of the last sentence was &lt;strong&gt;dynamic&lt;/strong&gt;?&lt;/p&gt;

&lt;p&gt;What makes Traefik really special is its ability of adding and removing container backend services by listening to Docker events.
So whenever a Docker container is started or stopped Traefik knows about it and adds the container to its list of active backend services.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/traefik/architecture.png&#34; alt=&#34;Traffic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;With this ability Traefik can replace much more complicated setups based on Nginx or HAProxy that have to use additional tools like
&lt;a href=&#34;https://github.com/gliderlabs/registrator&#34;&gt;Registrator&lt;/a&gt;, &lt;a href=&#34;https://www.consul.io/&#34;&gt;Consul&lt;/a&gt; and &lt;a href=&#34;https://github.com/hashicorp/consul-template&#34;&gt;Consul-Template&lt;/a&gt; to achieve the same kind of functionality.&lt;/p&gt;

&lt;p&gt;So let me show you with a simple microservice example how easy it is to get started with Traefik&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;As you can see in the following architecture overview we will have a simple HTTP service that answers incoming HTTP requests.&lt;/p&gt;

&lt;p&gt;We have multiple backend services that are running on different physical nodes for high availability and loadbalancing reasons.
Traefik serves as a frontend proxy that loadbalances incoming requests to the available backend services.&lt;/p&gt;

&lt;p&gt;Traefik as well as the backend services will run on top of a Docker Swarm cluster as containers.
In this example each backend service will answer with their individual container ID to make it easy to see which one answered.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/traefik/microsservice_example_end.jpg&#34; alt=&#34;Traffic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So to get started we need a running Docker Swarm Cluster first.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-docker-swarm-cluster&#34;&gt;Creating a Docker Swarm Cluster&lt;/h2&gt;

&lt;p&gt;One of fastest and easiest ways to get a Docker Swarm cluster running is to use our &lt;a href=&#34;https://github.com/hypriot/cluster-lab&#34;&gt;Hypriot Cluster Lab&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As the Cluster Lab comes already preinstalled with out latest HypriotOS &amp;ldquo;Barbossa&amp;rdquo; release for the Raspberr Pi I will show you how to set up a Swarm Cluster with that.&lt;/p&gt;

&lt;p&gt;To follow along you will need at least three Raspberry Pi&amp;rsquo;s. I will use my Pico-Cluster with five nodes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.hypriot.com/images/traefik/picocluster.jpg&#34; alt=&#34;Traffic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The first step is flashing the necessary SD card images with HypriotOS.&lt;/p&gt;

&lt;p&gt;Clone the Hypriot flash repository and change into the appropriate folder for the operating system you are using to flash the SD cards.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/hypriot/flash.gi://github.com/hypriot/flash.git
$ cd flash/Darwin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the flash tool ready we now can prepare the SD card for our &lt;strong&gt;leader node&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./flash --hostname cl-leader https://github.com/hypriot/image-builder-rpi/releases/download/v0.8.0/hypriotos-rpi-v0.8.0.img.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Repeat the process for the &lt;strong&gt;follower nodes&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in {1..4} do; ./flash --hostname cl-follower${i} https://github.com/hypriot/image-builder-rpi/releases/download/v0.8.0/hypriotos-rpi-v0.8.0.img.zip; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While the SD cards for the follower nodes are still being flashed you can already start the leader node.&lt;/p&gt;

&lt;p&gt;SSH into the leader and become root user:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh pirate@cl-leader.local
$ sudo su
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make the Cluster Lab work with Traefik we need to update to the most recent version:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apt-get update
$ apt-get install hypriot-cluster-lab=0.2.13-1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then start the Hypriot Cluster Lab with verbose output logging enabled:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ VERBOSE=true cluster-lab start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While the Cluster Lab starts you can see how it configures itself and does a number of self-tests.
If not all steps are green stop it and start it again. If that fails, too, have a look at our &lt;a href=&#34;https://github.com/hypriot/cluster-lab#troubleshooting&#34;&gt;troubleshooting section&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After the leader node is ready, it is time to boot the rest of our nodes and update and start the Cluster Lab in the same fashion.
So go ahead and come back when your are done.&lt;/p&gt;

&lt;p&gt;Allright, We can now check if we really have a healthy five nodes Swarm Cluster by executing the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOCKER_HOST=tcp://192.168.200.1:2378 docker info | grep Nodes
Nodes: 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And voila we now really have five nodes in our cluster.
Congrats!&lt;/p&gt;

&lt;p&gt;As you made it so far the rest will be a piece of a cake!&lt;/p&gt;

&lt;h3 id=&#34;setting-up-our-microservice-app-with-traefik&#34;&gt;Setting up our microservice app with Traefik&lt;/h3&gt;

&lt;p&gt;Our example microservice application consists of two parts. The Traefik frontend and the WhoAmI application backend.
For both parts I have prepared images for you that can be pulled from the Docker Hub.&lt;/p&gt;

&lt;p&gt;The Traefik image is called &lt;a href=&#34;https://hub.docker.com/r/hypriot/rpi-traefik/&#34;&gt;hypriot/rpi-traefik&lt;/a&gt; and the WhoAmI image is called &lt;a href=&#34;https://hub.docker.com/r/hypriot/rpi-whoami/&#34;&gt;hypriot/rpi-whoami&lt;/a&gt;.
The Dockerfiles for both images can be found on Github in the &lt;a href=&#34;https://github.com/hypriot&#34;&gt;related repositories&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Because both Dockerfiles are a fine example of how easy it is to create Docker images for Golang based software I will
show them here, too.&lt;/p&gt;

&lt;p&gt;Dockerfile for &amp;ldquo;rpi-traefik&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM hypriot/rpi-alpine-scratch
RUN apk update &amp;amp;&amp;amp;\
    apk upgrade &amp;amp;&amp;amp;\
    apk add ca-certificates &amp;amp;&amp;amp;\
    rm -rf /var/cache/apk/*
ADD https://github.com/containous/traefik/releases/download/v1.0.0-beta.771/traefik_linux-arm /traefik
RUN chmod +x /traefik
EXPOSE 80 8080
ENTRYPOINT [&amp;quot;/traefik&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we just add the Traefik binary on top of an Alpine linux image. The result is an image that is already quite small with about 41 MB.
It propably could be made even smaller by ensuring that the Traefik binary is compiled as a static binary and then putting it into an empty scratch image.&lt;/p&gt;

&lt;p&gt;You can see how this can be done with the next Dockerfile for the WhoAmI image:&lt;/p&gt;

&lt;p&gt;Dockerfile for &amp;ldquo;rpi-whoami&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM scratch

ADD http /http

ENV PORT 8000
EXPOSE 8000

CMD [&amp;quot;/http&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With about 3 MB the resulting image is really small.&lt;/p&gt;

&lt;p&gt;Well, now it is time to put this all together in a Docker Compose application.&lt;/p&gt;

&lt;p&gt;Clone the following repository on you cluster leader:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/hypriot/rpi-cluster-lab-demos
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When the cloning is finished change into the &amp;lsquo;traefik&amp;rsquo; folder and use Docker Compose to start our application on top of our little Docker Swarm cluster:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd rpi-cluster-lab-demos/traefik
$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose up -d
Creating network &amp;quot;traefik_default&amp;quot; with the default driver
Creating traefik_traefik_1
Creating traefik_whoami_1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this command Docker Compose should start two containers.
One Traefik container on our leader and one WhoAmi container on one of our follower nodes.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s check if that really happened:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker ps | grep &#39;traefik\|whoami&#39;
cba8d9a7d8f7        hypriot/rpi-whoami         &amp;quot;/http&amp;quot;                  About a minute ago   Up About a minute   8000/tcp                                                 cl-follower1/traefik_whoami_1
7dc2b48a24e2        hypriot/rpi-traefik        &amp;quot;/traefik --web --doc&amp;quot;   About a minute ago   Up About a minute   192.168.200.1:80-&amp;gt;80/tcp, 192.168.200.1:8080-&amp;gt;8080/tcp   cl-leader/traefik_traefik_1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks good. So let&amp;rsquo;s test our application by flinging some HTTP request towards our frontend:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in {1..5}; do curl -H Host:whoami.docker.localhost http://192.168.200.1; done
I&#39;am f72892c9187c
I&#39;am f72892c9187c
I&#39;am f72892c9187c
I&#39;am f72892c9187c
I&#39;am f72892c9187c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see it is always the same backend container which is responding and that&amp;rsquo;s just as it should be.&lt;/p&gt;

&lt;p&gt;Next we are going to increase the number of backend containers with the help of Docker Compose scale command.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose scale whoami=5
Creating and starting traefik_whoami_2 ... done
Creating and starting traefik_whoami_3 ... done
Creating and starting traefik_whoami_4 ... done
Creating and starting traefik_whoami_5 ... done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can watch as Docker Compose tells Docker Swarm to spin up more containers.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s verify again if we now have five backend containers running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ for i in {1..5}; do curl -H Host:whoami.docker.localhost http://192.168.200.1; done
I&#39;m 5d829fecbdaa
I&#39;m 5eb115353885
I&#39;m e0313ac24554
I&#39;m 642b5d2c8d09
I&#39;m f72892c9187c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect. Obviously Traefik did recognise that we started more containers and made them available to the frontend automatically.&lt;/p&gt;

&lt;p&gt;We can see what happened by looking at the logs of the Traefik container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose logs traefik
...
traefik_1  | time=&amp;quot;2016-06-07T06:50:38Z&amp;quot; level=debug msg=&amp;quot;Configuration received from provider docker: {\&amp;quot;backends\&amp;quot;:{\&amp;quot;backend-whoami\&amp;quot;:{\&amp;quot;servers\&amp;quot;:{\&amp;quot;server-traefik_whoami_1\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.3:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_2\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.5:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_3\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.6:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_4\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.4:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1},\&amp;quot;server-traefik_whoami_5\&amp;quot;:{\&amp;quot;url\&amp;quot;:\&amp;quot;http://10.0.0.7:8000\&amp;quot;,\&amp;quot;weight\&amp;quot;:1}}}},\&amp;quot;frontends\&amp;quot;:{\&amp;quot;frontend-Host-whoami-docker-localhost\&amp;quot;:{\&amp;quot;backend\&amp;quot;:\&amp;quot;backend-whoami\&amp;quot;,\&amp;quot;routes\&amp;quot;:{\&amp;quot;route-frontend-Host-whoami-docker-localhost\&amp;quot;:{\&amp;quot;rule\&amp;quot;:\&amp;quot;Host:whoami.docker.localhost\&amp;quot;}},\&amp;quot;passHostHeader\&amp;quot;:true}}}&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:38Z&amp;quot; level=debug msg=&amp;quot;Last docker config received less than 2s, waiting...&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Waited for docker config, OK&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating frontend frontend-Host-whoami-docker-localhost&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Wiring frontend frontend-Host-whoami-docker-localhost to entryPoint http&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating route route-frontend-Host-whoami-docker-localhost Host:whoami.docker.localhost&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating backend backend-whoami&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating load-balancer wrr&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_4 at http://10.0.0.4:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_3 at http://10.0.0.6:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_2 at http://10.0.0.5:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_1 at http://10.0.0.3:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=debug msg=&amp;quot;Creating server server-traefik_whoami_5 at http://10.0.0.7:8000 with weight 1&amp;quot;
traefik_1  | time=&amp;quot;2016-06-07T06:50:40Z&amp;quot; level=info msg=&amp;quot;Server configuration reloaded on :80&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looking at the logs we can now clearly see how Traefik catched the Docker event and how it reacted.&lt;/p&gt;

&lt;p&gt;Isnt&amp;rsquo; awesome?&lt;/p&gt;

&lt;p&gt;OK. So this was basically our quick tour on how to do set up a simple microservice example with Docker and Traefik.&lt;/p&gt;

&lt;p&gt;The only thing that is left for us now is to clean up again.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ DOCKER_HOST=tcp://192.168.200.1:2378 docker-compose down -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Did you notice the &amp;lsquo;-v&amp;rsquo; option? This seems to be really important as it cleans up all the containers including the overlay network that was created for us.
Without the &amp;lsquo;-v&amp;rsquo; option we would get an error the next time we start the application again with Docker Compose.&lt;/p&gt;

&lt;p&gt;It is also a good idea to stop the Cluster Lab on all nodes before you switch of your Raspberry Pi&amp;rsquo;s.&lt;/p&gt;

&lt;p&gt;So do a&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cluster-lab stop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;on all your cluster nodes.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s just amazing how many interesting technologies we used in this small blog post.
And it wasn&amp;rsquo;t to hard to get them running together, wasn&amp;rsquo;t it?&lt;/p&gt;

&lt;p&gt;That is mostly due to the work the &lt;a href=&#34;https://github.com/hypriot/cluster-lab&#34;&gt;Hypriot Cluster Lab&lt;/a&gt; does for us and of course under the hood it is the Docker-Engine, Docker-Swarm and Docker-Compose that let&amp;rsquo;s us do so much with so little effort.&lt;/p&gt;

&lt;p&gt;So make sure to give our Hypriot Cluster Lab a spin and try some of the examples in our &lt;a href=&#34;https://github.com/hypriot/rpi-cluster-lab-demos&#34;&gt;Hypriot Cluster Lab Demos&lt;/a&gt; repository or add some of your own. Pull requests are always welcome.&lt;/p&gt;

&lt;p&gt;As always use the comments below to give us feedback and share the news about this release on Twitter, Facebook or Google+.&lt;/p&gt;

&lt;p&gt;Govinda &lt;a href=&#34;https://twitter.com/_beagile_&#34;&gt;@_beagile__&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Let Docker Swarm all over your Raspberry Pi Cluster</title>
      <link>https://blog.hypriot.com/post/let-docker-swarm-all-over-your-raspberry-pi-cluster/</link>
      <pubDate>Fri, 03 Jul 2015 00:30:45 +0100</pubDate>
      
      <guid>https://blog.hypriot.com/post/let-docker-swarm-all-over-your-raspberry-pi-cluster/</guid>
      <description>&lt;p&gt;In this blog post we show you how easy it is to install Swarm on your Raspberry Pi and how to set up a Raspberry Pi Swarm cluster with the help of Docker Machine.&lt;/p&gt;

&lt;p&gt;We have built a little &amp;ldquo;Pi Tower&amp;rdquo; with three Raspberry Pi 2 model B and combined them into a Docker Swarm cluster.
&lt;/p&gt;

&lt;p&gt;As you can see in the pictures below we have mounted the three Raspberry Pi&amp;rsquo;s on top of a 5-port D-Link GBit switch. All four devices get their power from an Anker 4-port USB charger.
This makes a very solid but portable &amp;ldquo;Pi Tower&amp;rdquo; with only one power plug and one external network connector.&lt;/p&gt;

&lt;div class=&#34;gallery clearfix&#34; itemscope itemtype=&#34;http://schema.org/ImageGallery&#34;&gt;
&lt;div class=&#34;title&#34;&gt;Pi Tower&lt;/div&gt;




&lt;figure itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
  &lt;a href=&#34;https://blog.hypriot.com/images/docker-swarm/d-link_mounting_holes.jpg&#34; itemprop=&#34;contentUrl&#34; data-size=&#34;1600x1200&#34;&gt;
      &lt;img src=&#34;https://blog.hypriot.com/images/docker-swarm/thumbnails/thumb_d-link_mounting_holes.jpg&#34; itemprop=&#34;thumbnail&#34; alt=&#34;The Making of Pi Tower&#34; /&gt;
  &lt;/a&gt;


  &lt;figcaption itemprop=&#34;caption description&#34;&gt;
    The Making of Pi Tower
    &lt;span itemprop=&#34;copyrightHolder&#34;&gt;Hypriot&lt;/span&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;




&lt;figure itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
  &lt;a href=&#34;https://blog.hypriot.com/images/docker-swarm/d-link_rpi2_cluster.jpg&#34; itemprop=&#34;contentUrl&#34; data-size=&#34;1600x1200&#34;&gt;
      &lt;img src=&#34;https://blog.hypriot.com/images/docker-swarm/thumbnails/thumb_d-link_rpi2_cluster.jpg&#34; itemprop=&#34;thumbnail&#34; alt=&#34;Pi Tower with D-Link Switch&#34; /&gt;
  &lt;/a&gt;


  &lt;figcaption itemprop=&#34;caption description&#34;&gt;
    Pi Tower with D-Link Switch
    &lt;span itemprop=&#34;copyrightHolder&#34;&gt;Hypriot&lt;/span&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;




&lt;figure itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
  &lt;a href=&#34;https://blog.hypriot.com/images/docker-swarm/d-link_rpi2_cluster02.jpg&#34; itemprop=&#34;contentUrl&#34; data-size=&#34;1600x1200&#34;&gt;
      &lt;img src=&#34;https://blog.hypriot.com/images/docker-swarm/thumbnails/thumb_d-link_rpi2_cluster02.jpg&#34; itemprop=&#34;thumbnail&#34; alt=&#34;Pi Tower with D-Link Switch&#34; /&gt;
  &lt;/a&gt;


  &lt;figcaption itemprop=&#34;caption description&#34;&gt;
    Pi Tower with D-Link Switch
    &lt;span itemprop=&#34;copyrightHolder&#34;&gt;Hypriot&lt;/span&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;




&lt;figure itemscope itemtype=&#34;http://schema.org/ImageObject&#34;&gt;
  &lt;a href=&#34;https://blog.hypriot.com/images/docker-swarm/d-link_rpi2_cluster_lights.jpg&#34; itemprop=&#34;contentUrl&#34; data-size=&#34;1600x1200&#34;&gt;
      &lt;img src=&#34;https://blog.hypriot.com/images/docker-swarm/thumbnails/thumb_d-link_rpi2_cluster_lights.jpg&#34; itemprop=&#34;thumbnail&#34; alt=&#34;Pi Tower at night&#34; /&gt;
  &lt;/a&gt;


  &lt;figcaption itemprop=&#34;caption description&#34;&gt;
    Pi Tower at night
    &lt;span itemprop=&#34;copyrightHolder&#34;&gt;Hypriot&lt;/span&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;


&lt;/div&gt;


&lt;link rel=&#34;stylesheet&#34; href=&#34;https://blog.hypriot.com/css/photoswipe.css&#34;&gt;
&lt;link rel=&#34;stylesheet&#34; href=&#34;https://blog.hypriot.com/css/default-skin/default-skin.css&#34;&gt;
&lt;script src=&#34;https://blog.hypriot.com/js/photoswipe.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://blog.hypriot.com/js/photoswipe-ui-default.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://blog.hypriot.com/js/initphotoswipe.js&#34;&gt;&lt;/script&gt;



&lt;div class=&#34;pswp&#34; tabindex=&#34;-1&#34; role=&#34;dialog&#34; aria-hidden=&#34;true&#34;&gt;

&lt;div class=&#34;pswp__bg&#34;&gt;&lt;/div&gt;

&lt;div class=&#34;pswp__scroll-wrap&#34;&gt;
    
    &lt;div class=&#34;pswp__container&#34;&gt;
      &lt;div class=&#34;pswp__item&#34;&gt;&lt;/div&gt;
      &lt;div class=&#34;pswp__item&#34;&gt;&lt;/div&gt;
      &lt;div class=&#34;pswp__item&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div class=&#34;pswp__ui pswp__ui--hidden&#34;&gt;
    &lt;div class=&#34;pswp__top-bar&#34;&gt;
      
      &lt;div class=&#34;pswp__counter&#34;&gt;&lt;/div&gt;
      &lt;button class=&#34;pswp__button pswp__button--close&#34; title=&#34;Close (Esc)&#34;&gt;&lt;/button&gt;
      &lt;button class=&#34;pswp__button pswp__button--share&#34; title=&#34;Share&#34;&gt;&lt;/button&gt;
      &lt;button class=&#34;pswp__button pswp__button--fs&#34; title=&#34;Toggle fullscreen&#34;&gt;&lt;/button&gt;
      &lt;button class=&#34;pswp__button pswp__button--zoom&#34; title=&#34;Zoom in/out&#34;&gt;&lt;/button&gt;
      
      
      &lt;div class=&#34;pswp__preloader&#34;&gt;
        &lt;div class=&#34;pswp__preloader__icn&#34;&gt;
          &lt;div class=&#34;pswp__preloader__cut&#34;&gt;
            &lt;div class=&#34;pswp__preloader__donut&#34;&gt;&lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&#34;pswp__share-modal pswp__share-modal--hidden pswp__single-tap&#34;&gt;
      &lt;div class=&#34;pswp__share-tooltip&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    &lt;button class=&#34;pswp__button pswp__button--arrow--left&#34; title=&#34;Previous (arrow left)&#34;&gt;
    &lt;/button&gt;
    &lt;button class=&#34;pswp__button pswp__button--arrow--right&#34; title=&#34;Next (arrow right)&#34;&gt;
    &lt;/button&gt;
    &lt;div class=&#34;pswp__caption&#34;&gt;
      &lt;div class=&#34;pswp__caption__center&#34;&gt;&lt;/div&gt;
    &lt;/div&gt;
    &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;style&gt;
    .gallery {  }
    .gallery img { width: 100%; height: auto; }
    .gallery figure { display: block; float: left; margin: 0 5px 5px 0; width: 200px; }
    .gallery figcaption { display: none; }
    .gallery div.title { font-weight: bold; }
    span[itemprop=&#34;copyrightHolder&#34;] { color : #888; float: right; }
    span[itemprop=&#34;copyrightHolder&#34;]:before { content: &#34;Foto: &#34;; }
    img[itemprop=&#34;thumbnail&#34;]{ width: 200px; }
&lt;/style&gt;


&lt;script&gt;initPhotoSwipeFromDOM(&#39;.gallery&#39;);&lt;/script&gt;


&lt;p&gt;For your convenience we have prepared a &lt;a href=&#34;http://www.amazon.de/gp/registry/wishlist/BCGEW9W3V8GM/ref=cm_wl_rlist_go_o&#34;&gt;small shopping list&lt;/a&gt; of all the components we used at Amazon.&lt;/p&gt;

&lt;h2 id=&#34;pre-requisites&#34;&gt;Pre-requisites&lt;/h2&gt;

&lt;p&gt;For this tutorial we will run all steps from a Mac. To do this we need three tools.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A flash tool to write the SD card images for all the Raspberry Pi&amp;rsquo;s.&lt;/li&gt;
&lt;li&gt;The Docker client, which is only a &lt;code&gt;brew install docker&lt;/code&gt; away.&lt;/li&gt;
&lt;li&gt;The Docker Machine binary with the hypriot driver&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;flash-all-sd-cards&#34;&gt;Flash all SD cards&lt;/h2&gt;

&lt;p&gt;First we want to install the SD cards with Docker preinstalled.
On a Mac or Linux machine we can use our little &lt;a href=&#34;https://github.com/hypriot/flash&#34;&gt;flash command line tool&lt;/a&gt; to prepare the three SD cards with these simple commands:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ flash --hostname pi1 http://downloads.hypriot.com/hypriot-rpi-20150416-201537.img.zip
$ flash --hostname pi2 http://downloads.hypriot.com/hypriot-rpi-20150416-201537.img.zip
$ flash --hostname pi3 http://downloads.hypriot.com/hypriot-rpi-20150416-201537.img.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now insert the SD cards into all Raspberry Pi&amp;rsquo;s and boot them. They will come up with different host names after a while.&lt;/p&gt;

&lt;h2 id=&#34;retrieve-ip-addresses&#34;&gt;Retrieve IP addresses&lt;/h2&gt;

&lt;p&gt;Our SD card image also starts the avahi-daemon to announce the hostname through mDNS, so each Pi is reachable with &lt;code&gt;pi1.local&lt;/code&gt;, &lt;code&gt;pi2.local&lt;/code&gt; and &lt;code&gt;pi3.local&lt;/code&gt;.
Docker Machine cannot resolve these hostnames at the moment, so we have to retrieve the IP addresses for the Raspberry Pi&amp;rsquo;s manually.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ping -c 1 pi1.local
$ ping -c 1 pi2.local
$ ping -c 1 pi3.local
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For this example we assume that the three IP adresses are &lt;code&gt;192.168.1.101&lt;/code&gt;, &lt;code&gt;102&lt;/code&gt; and &lt;code&gt;103&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;insert-ssh-public-key&#34;&gt;Insert SSH public key&lt;/h2&gt;

&lt;p&gt;Docker Machine connects to each Raspberry Pi through SSH. You have to insert your public SSH key to avoid entering the password of the &lt;code&gt;root&lt;/code&gt; user.
To insert the SSH public key into a remote machine there is a tool called &lt;code&gt;ssh-copy-id&lt;/code&gt;. You might have to install it first.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ssh-copy-id root@192.168.1.101
$ ssh-copy-id root@192.168.1.102
$ ssh-copy-id root@192.168.1.103
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For each of the above commands you have to enter the password &lt;code&gt;hypriot&lt;/code&gt; for the user &lt;code&gt;root&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;create-docker-machines&#34;&gt;Create Docker Machines&lt;/h2&gt;

&lt;p&gt;For the next step we use our Docker Machine driver to connect to the Raspberry Pi Hypriot devices.
Our hypriot driver is not yet integrated into the official Docker Machine binary.
So we have to download the &lt;code&gt;docker-machine&lt;/code&gt; binary with our hypriot machine driver.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl -o docker-machine http://downloads.hypriot.com/docker-machine_0.4.0-dev_darwin-amd64
$ chmod +x ./docker-machine
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download the binary into the current directory and make it executable. You may move it
into another directory in your PATH to use it from other directories.&lt;/p&gt;

&lt;h3 id=&#34;create-swarm-token&#34;&gt;Create Swarm Token&lt;/h3&gt;

&lt;p&gt;A Docker Swarm cluster uses a unique Cluster ID which allows the individual swarm agents to find each other.
We need such a Cluster ID to build our Docker Swarm.&lt;/p&gt;

&lt;p&gt;This can be done in your shell with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ export TOKEN=$(for i in $(seq 1 32); do echo -n $(echo &amp;quot;obase=16; $(($RANDOM % 16))&amp;quot; | bc); done; echo)
$ echo $TOKEN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For this example we use&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ export TOKEN=babb1eb00bdecadedec0debabb1eb00b
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you already have a Docker swarm container up and running, you also can create a new Cluster ID
with &lt;code&gt;docker run --rm hypriot/rpi-swarm create&lt;/code&gt;.
We simply used the shell commands above to skip this chicken or egg problem.&lt;/p&gt;

&lt;h3 id=&#34;create-the-swarm-master&#34;&gt;Create the Swarm Master&lt;/h3&gt;

&lt;p&gt;Now we create the Docker Swarm Master on the first Raspberry Pi with our generated Cluster ID&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./docker-machine create -d hypriot --swarm --swarm-master --swarm-discovery token://$TOKEN --hypriot-ip-address 192.168.1.101 pi1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command connects to the Raspberry Pi &amp;ldquo;pi1&amp;rdquo;, secures the Docker daemon with TLS and pulls the Docker image &lt;code&gt;hypriot/rpi-swarm:latest&lt;/code&gt; from the Docker Hub.
It starts both the Swarm Master as well as a Swarm Agent in a container.&lt;/p&gt;

&lt;p&gt;To check if everything works we can connect to the newly started Swarm Master by using the following command.
It retrieves all environment variables needed for the Docker client to communicate with the Swarm.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ eval $(./docker-machine env --swarm pi1)
$ docker info
Containers: 2
Strategy: spread
Filters: affinity, health, constraint, port, dependency
Nodes: 1
 pi1: 192.168.1.202:2376
   Containers: 2
   Reserved CPUs: 0 / 4
   Reserved Memory: 0 B / 971.3 MiB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now have successfully set up a lonely Swarm Manager. Let&amp;rsquo;s start some more Raspberry Pi&amp;rsquo;s to prevent the Swarm Manager from feeling lonely.&lt;/p&gt;

&lt;h3 id=&#34;create-the-swarm-agents&#34;&gt;Create the Swarm agents&lt;/h3&gt;

&lt;p&gt;For the rest of the Raspberry Pi&amp;rsquo;s we also create Docker Machine connections with the same Cluster ID.
This time we run docker-machine without the &lt;code&gt;--swarm-master&lt;/code&gt; option to just spin up a Swarm Agent container in each Pi.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./docker-machine create -d hypriot --swarm --swarm-discovery token://$TOKEN --hypriot-ip-address 192.168.1.102 pi2
$ ./docker-machine create -d hypriot --swarm --swarm-discovery token://$TOKEN --hypriot-ip-address 192.168.1.103 pi3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s check what the swarm looks like now&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker info
Containers: 4
Strategy: spread
Filters: affinity, health, constraint, port, dependency
Nodes: 3
 pi1: 192.168.1.101:2376
   Containers: 2
   Reserved CPUs: 0 / 4
   Reserved Memory: 0 B / 971.3 MiB
 pi2: 192.168.1.102:2376
   Containers: 1
   Reserved CPUs: 0 / 4
   Reserved Memory: 0 B / 971.3 MiB
 pi3: 192.168.1.103:2376
   Containers: 1
   Reserved CPUs: 0 / 4
   Reserved Memory: 0 B / 971.3 MiB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We also can list all containers in the whole swarm as usual with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker ps
CONTAINER ID        IMAGE                      COMMAND                CREATED             STATUS              PORTS                                    NAMES
5effaa7de4a3        hypriot/rpi-swarm:latest   &amp;quot;/swarm join --addr    2 minutes ago       Up About a minute   2375/tcp                                 pi3/swarm-agent
6b73003b7246        hypriot/rpi-swarm:latest   &amp;quot;/swarm join --addr    4 minutes ago       Up 3 minutes        2375/tcp                                 pi2/swarm-agent
5e00fbf7b9f6        hypriot/rpi-swarm:latest   &amp;quot;/swarm join --addr    7 minutes ago       Up 7 minutes        2375/tcp                                 pi1/swarm-agent
02c905ec25a0        hypriot/rpi-swarm:latest   &amp;quot;/swarm manage --tls   7 minutes ago       Up 7 minutes        2375/tcp, 192.168.1.101:3376-&amp;gt;3376/tcp   pi1/swarm-agent-master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After setting up the Docker Swarm you now can use the normal Docker commands through port 3376.
Have a look at the &lt;a href=&#34;https://docs.docker.com/swarm/&#34;&gt;official Docker Swarm documentation&lt;/a&gt; for more details.&lt;/p&gt;

&lt;p&gt;Just remember to set up the environment correctly to communicate with the Swarm Master before using the Docker client by&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ eval $(docker-machine env --swarm pi1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then you can remotely manage your Raspberry Pi Swarm from your Mac. See - this was not really difficult, was it?&lt;/p&gt;

&lt;p&gt;We hope you enjoyed this little tour of Docker Swarm!&lt;/p&gt;

&lt;p&gt;As always use the comments below to give us feedback and share it on Twitter or Facebook.&lt;/p&gt;

&lt;p&gt;Stefan&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>